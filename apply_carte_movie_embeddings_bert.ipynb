{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARTE + BERT 하이브리드 임베딩\n",
    "\n",
    "기존 CARTE 파이프라인에 BERT 텍스트 임베딩을 추가하는 버전.\n",
    "\n",
    "**하이브리드 방식:**\n",
    "- `tagline`, `overview` → BERT (sentence-transformers)\n",
    "- 나머지 피처 (actor, director, genre 등) → fastText (기존 방식)\n",
    "\n",
    "**구현 방식:**\n",
    "1. BERT로 tagline+overview 임베딩 (768차원)\n",
    "2. Linear projection으로 300차원 축소\n",
    "3. graphlet에 BERT 임베딩 노드 추가\n",
    "4. CARTE 모델로 최종 임베딩 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 의존성 설치 (필요시)\n",
    "# !pip install sentence-transformers torch_geometric carte_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jisoo/projects/thesis/carte_test/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/jisoo/projects/thesis/carte_test\n",
      "Output path: /Users/jisoo/projects/thesis/carte_test/data/processed/movie_embeddings_bert.parquet\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Mapping, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from huggingface_hub import hf_hub_download\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# CARTE\n",
    "from carte_ai import Table2GraphTransformer\n",
    "from carte_ai.src.carte_model import CARTE_Base\n",
    "from carte_ai.configs.directory import config_directory\n",
    "\n",
    "# 프로젝트 설정\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "from config import PROCESSED, PROJECT_ROOT\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Output path: {PROCESSED.MOVIE_EMBEDDINGS_BERT_PARQUET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 설정\n",
    "# ============================================================\n",
    "@dataclass(frozen=True)\n",
    "class CatalogSchema:\n",
    "    \"\"\"입력 catalog 스키마 정의\"\"\"\n",
    "    id_col: str = \"movieId\"\n",
    "    \n",
    "    # BERT로 임베딩할 텍스트 컬럼\n",
    "    bert_text_cols: Tuple[str, ...] = (\"tagline\", \"overview\")\n",
    "    \n",
    "    # fastText로 임베딩할 컬럼 (기존 방식 유지)\n",
    "    num_cols: Tuple[str, ...] = (\"release_year\",)\n",
    "    text_cols_slot: Tuple[str, ...] = (\n",
    "        \"produced_by_company_1\",\n",
    "        \"produced_in_country_1\",\n",
    "        \"spoken_language_1\",\n",
    "        \"actor_1\", \"actor_2\", \"actor_3\",\n",
    "        \"director_1\", \"writer_1\",\n",
    "        \"genre_1\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def required_cols(self) -> Tuple[str, ...]:\n",
    "        return (self.id_col, *self.bert_text_cols, *self.num_cols, *self.text_cols_slot)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RunConfig:\n",
    "    \"\"\"실행 파라미터\"\"\"\n",
    "    input_path: Path\n",
    "    out_path: Path\n",
    "    pretrained_model_path: Path\n",
    "    batch_size: int = 256\n",
    "    device: str = \"cpu\"\n",
    "    num_layers: int = 0\n",
    "    verbose: bool = True\n",
    "    \n",
    "    # BERT 설정\n",
    "    bert_model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\"  # 384차원\n",
    "    bert_batch_size: int = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BERT 임베딩 생성\n",
    "# ============================================================\n",
    "def combine_text_fields(row: pd.Series, text_cols: Tuple[str, ...]) -> str:\n",
    "    \"\"\"여러 텍스트 컬럼을 하나의 문자열로 결합\"\"\"\n",
    "    parts = []\n",
    "    for col in text_cols:\n",
    "        val = row.get(col)\n",
    "        if pd.notna(val) and str(val).strip():\n",
    "            parts.append(str(val).strip())\n",
    "    return \" \".join(parts) if parts else \"\"\n",
    "\n",
    "\n",
    "def compute_bert_embeddings(\n",
    "    df: pd.DataFrame,\n",
    "    text_cols: Tuple[str, ...],\n",
    "    model_name: str,\n",
    "    batch_size: int = 64,\n",
    "    device: str = \"cpu\",\n",
    "    verbose: bool = True,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    BERT(sentence-transformers)로 텍스트 임베딩 생성\n",
    "    \n",
    "    Returns:\n",
    "        (N, bert_dim) 배열\n",
    "    \"\"\"\n",
    "    # 텍스트 결합\n",
    "    texts = df.apply(lambda row: combine_text_fields(row, text_cols), axis=1).tolist()\n",
    "    \n",
    "    # 빈 텍스트 처리\n",
    "    texts = [t if t else \"[empty]\" for t in texts]\n",
    "    \n",
    "    if verbose:\n",
    "        non_empty = sum(1 for t in texts if t != \"[empty]\")\n",
    "        print(f\"[BERT] Non-empty texts: {non_empty:,} / {len(texts):,}\")\n",
    "        print(f\"[BERT] Sample text: {texts[0][:200]}...\")\n",
    "    \n",
    "    # 모델 로드\n",
    "    model = SentenceTransformer(model_name, device=device)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"[BERT] Model: {model_name}\")\n",
    "        print(f\"[BERT] Embedding dim: {model.get_sentence_embedding_dimension()}\")\n",
    "    \n",
    "    # 임베딩 생성\n",
    "    embeddings = model.encode(\n",
    "        texts,\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=verbose,\n",
    "        convert_to_numpy=True,\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"[BERT] Output shape: {embeddings.shape}\")\n",
    "    \n",
    "    return embeddings.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 차원 축소 (BERT dim → 300)\n",
    "# ============================================================\n",
    "class LinearProjection(nn.Module):\n",
    "    \"\"\"BERT 임베딩을 CARTE 입력 차원(300)으로 projection\"\"\"\n",
    "    def __init__(self, input_dim: int, output_dim: int = 300):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.LayerNorm(output_dim),\n",
    "        )\n",
    "        # Xavier 초기화\n",
    "        nn.init.xavier_uniform_(self.proj[0].weight)\n",
    "        nn.init.zeros_(self.proj[0].bias)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.proj(x)\n",
    "\n",
    "\n",
    "def project_bert_to_300(\n",
    "    bert_emb: np.ndarray,\n",
    "    device: str = \"cpu\",\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    BERT 임베딩을 300차원으로 projection\n",
    "    학습 없이 고정 projection 사용\n",
    "    \"\"\"\n",
    "    input_dim = bert_emb.shape[1]\n",
    "    \n",
    "    # 고정 시드로 재현 가능한 projection\n",
    "    torch.manual_seed(42)\n",
    "    proj = LinearProjection(input_dim, 300).to(device)\n",
    "    proj.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x = torch.from_numpy(bert_emb).to(device)\n",
    "        out = proj(x)\n",
    "        return out.cpu().numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Graphlet에 BERT 노드 추가\n",
    "# ============================================================\n",
    "def add_bert_node_to_graphlet(\n",
    "    graph: Data,\n",
    "    bert_vec: np.ndarray,\n",
    ") -> Data:\n",
    "    \"\"\"\n",
    "    기존 graphlet에 BERT 임베딩 노드를 추가\n",
    "    \n",
    "    - 새 노드를 head node(인덱스 0)와 연결\n",
    "    - edge_attr는 BERT 벡터 자체를 사용\n",
    "    \"\"\"\n",
    "    old_x = graph.x  # (num_nodes, 300)\n",
    "    old_edge_index = graph.edge_index  # (2, num_edges)\n",
    "    old_edge_attr = graph.edge_attr  # (num_edges, 300)\n",
    "    \n",
    "    num_old_nodes = old_x.shape[0]\n",
    "    new_node_idx = num_old_nodes\n",
    "    \n",
    "    # 새 노드 피처 추가 (BERT 벡터)\n",
    "    bert_node = torch.from_numpy(bert_vec).unsqueeze(0)  # (1, 300)\n",
    "    new_x = torch.cat([old_x, bert_node], dim=0)  # (num_nodes+1, 300)\n",
    "    \n",
    "    # 새 엣지 추가: head(0) <-> bert_node (양방향)\n",
    "    new_edges = torch.tensor([[0, new_node_idx], [new_node_idx, 0]], dtype=torch.long)\n",
    "    new_edge_index = torch.cat([old_edge_index, new_edges], dim=1)\n",
    "    \n",
    "    # 새 엣지 속성: BERT 벡터 사용\n",
    "    new_edge_attrs = torch.from_numpy(np.stack([bert_vec, bert_vec]))  # (2, 300)\n",
    "    new_edge_attr = torch.cat([old_edge_attr, new_edge_attrs], dim=0)\n",
    "    \n",
    "    # 새 Data 객체 생성\n",
    "    return Data(\n",
    "        x=new_x,\n",
    "        edge_index=new_edge_index,\n",
    "        edge_attr=new_edge_attr,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 기존 유틸리티 함수들 (apply_carte_movie_embeddings.ipynb에서 가져옴)\n",
    "# ============================================================\n",
    "def normalize_text(v: Any) -> Optional[str]:\n",
    "    \"\"\"문자열 정규화\"\"\"\n",
    "    if v is None:\n",
    "        return None\n",
    "    if isinstance(v, float) and np.isnan(v):\n",
    "        return None\n",
    "    s = str(v)\n",
    "    s = re.sub(r\"\\s+\", \" \", s.strip())\n",
    "    return s if s else None\n",
    "\n",
    "\n",
    "def extract_state_dict(ckpt_obj: Any) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"체크포인트에서 state_dict 추출\"\"\"\n",
    "    if hasattr(ckpt_obj, \"state_dict\") and callable(getattr(ckpt_obj, \"state_dict\")):\n",
    "        return dict(ckpt_obj.state_dict())\n",
    "    if isinstance(ckpt_obj, Mapping):\n",
    "        for key in (\"state_dict\", \"model_state_dict\", \"model\", \"net\"):\n",
    "            if key in ckpt_obj and isinstance(ckpt_obj[key], Mapping):\n",
    "                return dict(ckpt_obj[key])\n",
    "        tensor_cnt = sum(isinstance(v, torch.Tensor) for v in ckpt_obj.values())\n",
    "        if tensor_cnt >= max(1, len(ckpt_obj) // 3):\n",
    "            return dict(ckpt_obj)\n",
    "    raise ValueError(\"checkpoint에서 state_dict를 찾지 못했습니다.\")\n",
    "\n",
    "\n",
    "def strip_common_prefixes(state: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"공통 prefix 제거\"\"\"\n",
    "    prefixes = (\"model.\", \"module.\", \"ft_base.\")\n",
    "    out: Dict[str, torch.Tensor] = {}\n",
    "    for k, v in state.items():\n",
    "        nk = k\n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed = False\n",
    "            for p in prefixes:\n",
    "                if nk.startswith(p):\n",
    "                    nk = nk[len(p):]\n",
    "                    changed = True\n",
    "        out[nk] = v\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_device(device: Optional[str]) -> str:\n",
    "    \"\"\"device 자동 선택\"\"\"\n",
    "    if device is None or str(device).strip() == \"\":\n",
    "        return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    return str(device).strip()\n",
    "\n",
    "\n",
    "def resolve_pretrained_path(user_path: str = \"\") -> Path:\n",
    "    \"\"\"pretrained 경로 결정\"\"\"\n",
    "    if user_path.strip():\n",
    "        return Path(user_path.strip())\n",
    "    default_path = str(config_directory.get(\"pretrained_model\", \"\")).strip()\n",
    "    if not default_path:\n",
    "        raise ValueError(\"pretrained_model_path가 비어있습니다.\")\n",
    "    return Path(default_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 모델 로딩\n",
    "# ============================================================\n",
    "def load_carte_base(\n",
    "    *,\n",
    "    pretrained_model_path: Path,\n",
    "    device: str,\n",
    "    num_layers: int,\n",
    "    verbose: bool,\n",
    ") -> CARTE_Base:\n",
    "    \"\"\"pretrained CARTE_Base 로드\"\"\"\n",
    "    ckpt_path = Path(pretrained_model_path)\n",
    "    if not ckpt_path.exists():\n",
    "        raise FileNotFoundError(f\"[CKPT] file not found: {ckpt_path}\")\n",
    "\n",
    "    ckpt_obj = torch.load(str(ckpt_path), map_location=\"cpu\")\n",
    "    raw_state = extract_state_dict(ckpt_obj)\n",
    "    state = strip_common_prefixes(raw_state)\n",
    "\n",
    "    # 하이퍼파라미터 추론\n",
    "    w = state.get(\"initial_x.0.weight\")\n",
    "    hidden_dim = int(w.shape[0])\n",
    "    input_dim_x = int(w.shape[1])\n",
    "    input_dim_e = input_dim_x\n",
    "    ff_dim = hidden_dim\n",
    "    num_heads = 12 if hidden_dim % 12 == 0 else 1\n",
    "\n",
    "    model = CARTE_Base(\n",
    "        input_dim_x=input_dim_x,\n",
    "        input_dim_e=input_dim_e,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=int(num_layers),\n",
    "        ff_dim=int(ff_dim),\n",
    "        num_heads=int(num_heads),\n",
    "        concat=True,\n",
    "        dropout=0.0,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(state, strict=False)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[Model] hidden_dim={hidden_dim} num_layers={num_layers}\")\n",
    "        print(f\"[Model] Loaded from: {ckpt_path}\")\n",
    "\n",
    "    model = model.to(torch.device(device))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Head embedding 추출\n",
    "# ============================================================\n",
    "@torch.no_grad()\n",
    "def extract_head_embeddings(\n",
    "    graphs: List[Data],\n",
    "    *,\n",
    "    model: CARTE_Base,\n",
    "    batch_size: int,\n",
    "    device: str,\n",
    "    verbose: bool,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"각 graphlet의 head node embedding 추출\"\"\"\n",
    "    if not graphs:\n",
    "        raise ValueError(\"graphs가 비어있습니다.\")\n",
    "\n",
    "    loader = DataLoader(graphs, batch_size=int(batch_size), shuffle=False)\n",
    "\n",
    "    outs: List[np.ndarray] = []\n",
    "    for step, batch in enumerate(tqdm(loader, disable=not verbose, desc=\"Extracting embeddings\")):\n",
    "        batch = batch.to(torch.device(device))\n",
    "        x_out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        \n",
    "        # head indices from ptr\n",
    "        head_idx = batch.ptr[:-1] if hasattr(batch, \"ptr\") else torch.arange(len(batch))\n",
    "        head_emb = x_out[head_idx].detach().cpu().numpy()\n",
    "        outs.append(head_emb)\n",
    "\n",
    "    emb = np.vstack(outs)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"[Embeddings] shape: {emb.shape}\")\n",
    "    \n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 메인 파이프라인\n",
    "# ============================================================\n",
    "def run_hybrid_pipeline(cfg: RunConfig, schema: CatalogSchema) -> Path:\n",
    "    \"\"\"\n",
    "    BERT + CARTE 하이브리드 파이프라인\n",
    "    \n",
    "    1. 카탈로그 로드\n",
    "    2. BERT로 tagline+overview 임베딩\n",
    "    3. Table2GraphTransformer로 기본 graphlet 생성\n",
    "    4. 각 graphlet에 BERT 노드 추가\n",
    "    5. CARTE 모델로 최종 임베딩 생성\n",
    "    \"\"\"\n",
    "    if not cfg.input_path.exists():\n",
    "        raise FileNotFoundError(f\"input_path not found: {cfg.input_path}\")\n",
    "\n",
    "    cfg.out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if cfg.verbose:\n",
    "        print(f\"[IO] input: {cfg.input_path}\")\n",
    "        print(f\"[IO] output: {cfg.out_path}\")\n",
    "        print(f\"[Config] BERT model: {cfg.bert_model_name}\")\n",
    "        print(f\"[Config] device: {cfg.device}\")\n",
    "\n",
    "    # 1) 카탈로그 로드\n",
    "    df_raw = pd.read_parquet(cfg.input_path)\n",
    "    \n",
    "    # 필수 컬럼 확인\n",
    "    missing = [c for c in schema.required_cols if c not in df_raw.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "    \n",
    "    df = df_raw.dropna(subset=[schema.id_col]).reset_index(drop=True)\n",
    "    movie_ids = df[schema.id_col].astype(int).to_numpy()\n",
    "    \n",
    "    if cfg.verbose:\n",
    "        print(f\"[Data] rows: {len(df):,}\")\n",
    "\n",
    "    # 2) BERT 임베딩 생성\n",
    "    print(\"\\n=== Step 1: BERT Embedding ===\")\n",
    "    bert_emb = compute_bert_embeddings(\n",
    "        df,\n",
    "        schema.bert_text_cols,\n",
    "        model_name=cfg.bert_model_name,\n",
    "        batch_size=cfg.bert_batch_size,\n",
    "        device=cfg.device,\n",
    "        verbose=cfg.verbose,\n",
    "    )\n",
    "    \n",
    "    # 3) BERT 임베딩을 300차원으로 projection\n",
    "    print(\"\\n=== Step 2: Dimension Projection ===\")\n",
    "    bert_300 = project_bert_to_300(bert_emb, device=cfg.device)\n",
    "    if cfg.verbose:\n",
    "        print(f\"[Projection] {bert_emb.shape} -> {bert_300.shape}\")\n",
    "\n",
    "    # 4) fastText 기반 graphlet 생성 (기존 방식)\n",
    "    print(\"\\n=== Step 3: Building Graphlets (fastText) ===\")\n",
    "    \n",
    "    # 기존 피처 테이블 준비\n",
    "    X_fasttext = df.loc[:, [*schema.num_cols, *schema.text_cols_slot]].copy()\n",
    "    \n",
    "    # numeric: NaN 유지\n",
    "    for c in schema.num_cols:\n",
    "        X_fasttext[c] = pd.to_numeric(X_fasttext[c], errors=\"coerce\")\n",
    "    \n",
    "    # text: 정규화\n",
    "    for c in schema.text_cols_slot:\n",
    "        X_fasttext[c] = X_fasttext[c].apply(normalize_text).astype(\"object\")\n",
    "    \n",
    "    # fastText 모델 다운로드 및 graphlet 생성\n",
    "    fasttext_bin_path = hf_hub_download(\n",
    "        repo_id=\"hi-paris/fastText\",\n",
    "        filename=\"cc.en.300.bin\",\n",
    "    )\n",
    "    \n",
    "    preprocessor = Table2GraphTransformer(\n",
    "        lm_model=\"fasttext\",\n",
    "        fasttext_model_path=fasttext_bin_path,\n",
    "    )\n",
    "    \n",
    "    graphs = preprocessor.fit_transform(X_fasttext)\n",
    "    \n",
    "    if cfg.verbose:\n",
    "        print(f\"[Graphlets] count: {len(graphs):,}\")\n",
    "        g0 = graphs[0]\n",
    "        print(f\"[Graphlets] sample0: x={tuple(g0.x.shape)}, edge_attr={tuple(g0.edge_attr.shape)}\")\n",
    "\n",
    "    # 5) 각 graphlet에 BERT 노드 추가\n",
    "    print(\"\\n=== Step 4: Adding BERT Nodes to Graphlets ===\")\n",
    "    graphs_with_bert = []\n",
    "    for i, (g, bv) in enumerate(tqdm(zip(graphs, bert_300), total=len(graphs), desc=\"Adding BERT nodes\", disable=not cfg.verbose)):\n",
    "        g_new = add_bert_node_to_graphlet(g, bv)\n",
    "        graphs_with_bert.append(g_new)\n",
    "    \n",
    "    if cfg.verbose:\n",
    "        g0_new = graphs_with_bert[0]\n",
    "        print(f\"[Graphlets+BERT] sample0: x={tuple(g0_new.x.shape)}, edge_attr={tuple(g0_new.edge_attr.shape)}\")\n",
    "\n",
    "    # 6) CARTE 모델 로드\n",
    "    print(\"\\n=== Step 5: Loading CARTE Model ===\")\n",
    "    model = load_carte_base(\n",
    "        pretrained_model_path=cfg.pretrained_model_path,\n",
    "        device=cfg.device,\n",
    "        num_layers=cfg.num_layers,\n",
    "        verbose=cfg.verbose,\n",
    "    )\n",
    "\n",
    "    # 7) 임베딩 추출\n",
    "    print(\"\\n=== Step 6: Extracting Embeddings ===\")\n",
    "    emb = extract_head_embeddings(\n",
    "        graphs_with_bert,\n",
    "        model=model,\n",
    "        batch_size=cfg.batch_size,\n",
    "        device=cfg.device,\n",
    "        verbose=cfg.verbose,\n",
    "    )\n",
    "\n",
    "    # 8) 저장\n",
    "    out_df = pd.DataFrame({\n",
    "        schema.id_col: movie_ids,\n",
    "        \"embedding\": [e.astype(np.float32).tolist() for e in emb],\n",
    "    })\n",
    "    out_df.to_parquet(cfg.out_path, index=False)\n",
    "\n",
    "    if cfg.verbose:\n",
    "        print(f\"\\n[OK] Saved: {cfg.out_path}\")\n",
    "        print(f\"[OK] rows={len(out_df):,}, dim={emb.shape[1]}\")\n",
    "\n",
    "    return cfg.out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "BERT model: sentence-transformers/all-MiniLM-L6-v2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 실행\n",
    "# ============================================================\n",
    "schema = CatalogSchema()\n",
    "\n",
    "cfg = RunConfig(\n",
    "    input_path=PROCESSED.MOVIE_CATALOG_PARQUET,\n",
    "    out_path=PROCESSED.MOVIE_EMBEDDINGS_BERT_PARQUET,\n",
    "    pretrained_model_path=resolve_pretrained_path(),\n",
    "    batch_size=256,\n",
    "    device=build_device(None),  # auto-detect\n",
    "    num_layers=0,\n",
    "    verbose=True,\n",
    "    bert_model_name=\"sentence-transformers/all-MiniLM-L6-v2\",  # 빠른 모델 (384차원)\n",
    "    bert_batch_size=64,\n",
    ")\n",
    "\n",
    "print(f\"Device: {cfg.device}\")\n",
    "print(f\"BERT model: {cfg.bert_model_name}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IO] input: /Users/jisoo/projects/thesis/carte_test/data/processed/movie_catalog_flat.parquet\n",
      "[IO] output: /Users/jisoo/projects/thesis/carte_test/data/processed/movie_embeddings_bert.parquet\n",
      "[Config] BERT model: sentence-transformers/all-MiniLM-L6-v2\n",
      "[Config] device: cpu\n",
      "[Data] rows: 86,272\n",
      "\n",
      "=== Step 1: BERT Embedding ===\n",
      "[BERT] Non-empty texts: 85,995 / 86,272\n",
      "[BERT] Sample text: ... look closer Lester Burnham, a depressed suburban father in a mid-life crisis, decides to turn his hectic life around after developing an infatuation with his daughter's attractive friend....\n",
      "[BERT] Model: sentence-transformers/all-MiniLM-L6-v2\n",
      "[BERT] Embedding dim: 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1348/1348 [07:39<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT] Output shape: (86272, 384)\n",
      "\n",
      "=== Step 2: Dimension Projection ===\n",
      "[Projection] (86272, 384) -> (86272, 300)\n",
      "\n",
      "=== Step 3: Building Graphlets (fastText) ===\n",
      "[Graphlets] count: 86,272\n",
      "[Graphlets] sample0: x=(11, 300), edge_attr=(20, 300)\n",
      "\n",
      "=== Step 4: Adding BERT Nodes to Graphlets ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding BERT nodes: 100%|██████████| 86272/86272 [00:06<00:00, 12921.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Graphlets+BERT] sample0: x=(12, 300), edge_attr=(22, 300)\n",
      "\n",
      "=== Step 5: Loading CARTE Model ===\n",
      "[Model] hidden_dim=300 num_layers=0\n",
      "[Model] Loaded from: /Users/jisoo/projects/thesis/carte_test/.venv/lib/python3.11/site-packages/carte_ai/data/etc/kg_pretrained.pt\n",
      "\n",
      "=== Step 6: Extracting Embeddings ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 337/337 [00:14<00:00, 23.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Embeddings] shape: (86272, 300)\n",
      "\n",
      "[OK] Saved: /Users/jisoo/projects/thesis/carte_test/data/processed/movie_embeddings_bert.parquet\n",
      "[OK] rows=86,272, dim=300\n",
      "\n",
      "Output saved to: /Users/jisoo/projects/thesis/carte_test/data/processed/movie_embeddings_bert.parquet\n"
     ]
    }
   ],
   "source": [
    "# 파이프라인 실행\n",
    "out_path = run_hybrid_pipeline(cfg, schema)\n",
    "print(f\"\\nOutput saved to: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (86272, 300)\n",
      "Norm range: [nan, nan]\n",
      "\n",
      "Random pair cosine similarity:\n",
      "  mean: nan\n",
      "  std:  nan\n",
      "  p5:   nan\n",
      "  p50:  nan\n",
      "  p95:  nan\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 결과 확인 (간단 진단)\n",
    "# ============================================================\n",
    "df_result = pd.read_parquet(out_path)\n",
    "emb_list = df_result[\"embedding\"].tolist()\n",
    "E = np.array(emb_list, dtype=np.float32)\n",
    "\n",
    "print(f\"Shape: {E.shape}\")\n",
    "print(f\"Norm range: [{E.min():.4f}, {E.max():.4f}]\")\n",
    "\n",
    "# 정규화 후 랜덤 쌍 코사인 유사도\n",
    "E_norm = E / (np.linalg.norm(E, axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "n = min(10000, len(E))\n",
    "idx_a = rng.integers(0, len(E), size=n)\n",
    "idx_b = rng.integers(0, len(E), size=n)\n",
    "cos_sim = np.sum(E_norm[idx_a] * E_norm[idx_b], axis=1)\n",
    "\n",
    "print(f\"\\nRandom pair cosine similarity:\")\n",
    "print(f\"  mean: {cos_sim.mean():.4f}\")\n",
    "print(f\"  std:  {cos_sim.std():.4f}\")\n",
    "print(f\"  p5:   {np.percentile(cos_sim, 5):.4f}\")\n",
    "print(f\"  p50:  {np.percentile(cos_sim, 50):.4f}\")\n",
    "print(f\"  p95:  {np.percentile(cos_sim, 95):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
