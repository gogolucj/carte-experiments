{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer 기반 Rating 예측 모델\n",
    "\n",
    "유저의 시청 이력 (영화 임베딩 + 평점)을 바탕으로 새로운 영화의 평점을 예측\n",
    "\n",
    "## 모델 구조\n",
    "```\n",
    "Input:\n",
    "  - History: [(emb_1, rating_1), (emb_2, rating_2), ..., (emb_t, rating_t)]\n",
    "  - Query: emb_query (평점을 예측할 영화)\n",
    "       ↓\n",
    "  [emb + rating_embedding] for each history item\n",
    "       ↓\n",
    "  Transformer Encoder (시청 이력 인코딩)\n",
    "       ↓\n",
    "  Cross-Attention with Query embedding\n",
    "       ↓\n",
    "  MLP Head → Predicted Rating (1.0 ~ 5.0)\n",
    "```\n",
    "\n",
    "## 학습 방식\n",
    "- Input: 유저의 과거 시청 이력 + 타겟 영화 임베딩\n",
    "- Target: 타겟 영화에 대한 실제 평점\n",
    "- Loss: MSE (Mean Squared Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jisoo/projects/thesis/carte_test/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# MPS fallback 설정\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "sys.path.insert(0, \"/Users/jisoo/projects/thesis/carte_test\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "\n",
    "from config import PROCESSED\n",
    "\n",
    "# 한글 폰트\n",
    "if platform.system() == 'Darwin':\n",
    "    plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# Device\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평점 수: 13,717,662\n",
      "유저 수: 200,948\n",
      "영화 수: 54,520\n",
      "평점 분포:\n",
      "rating\n",
      "0.5     196137\n",
      "1.0     388549\n",
      "1.5     168463\n",
      "2.0     763558\n",
      "2.5     526958\n",
      "3.0    2552185\n",
      "3.5    1550226\n",
      "4.0    3769455\n",
      "4.5    1371038\n",
      "5.0    2431093\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 평점 데이터 로드\n",
    "ratings = pd.read_parquet(PROCESSED.RATINGS_PARQUET)\n",
    "print(f\"평점 수: {len(ratings):,}\")\n",
    "print(f\"유저 수: {ratings['userId'].nunique():,}\")\n",
    "print(f\"영화 수: {ratings['movieId'].nunique():,}\")\n",
    "print(f\"평점 분포:\")\n",
    "print(ratings['rating'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 영화 수: 53,630\n",
      "임베딩 차원: 300\n"
     ]
    }
   ],
   "source": [
    "# KG+BERT 임베딩 로드\n",
    "EMB_PATH = PROCESSED.DIR / \"ablation_embeddings\" / \"emb_kg_gnn_bert.parquet\"\n",
    "\n",
    "if not EMB_PATH.exists():\n",
    "    print(f\"Warning: {EMB_PATH} not found, trying kg_gnn...\")\n",
    "    EMB_PATH = PROCESSED.DIR / \"ablation_embeddings\" / \"emb_kg_gnn.parquet\"\n",
    "\n",
    "emb_df = pd.read_parquet(EMB_PATH)\n",
    "print(f\"임베딩 영화 수: {len(emb_df):,}\")\n",
    "\n",
    "# 임베딩 행렬 생성\n",
    "movie_ids = emb_df['movieId'].to_numpy()\n",
    "embeddings = np.array(emb_df['embedding'].tolist(), dtype=np.float32)\n",
    "emb_dim = embeddings.shape[1]\n",
    "print(f\"임베딩 차원: {emb_dim}\")\n",
    "\n",
    "# movieId → index 매핑\n",
    "movie_to_idx = {mid: i for i, mid in enumerate(movie_ids)}\n",
    "idx_to_movie = {i: mid for mid, i in movie_to_idx.items()}\n",
    "\n",
    "# 정규화\n",
    "norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "embeddings_norm = embeddings / (norms + 1e-12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 시퀀스 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필터링 후 평점 수: 13,680,490\n",
      "샘플링 후 평점 수: 137,588 (2,000 유저)\n",
      "유저별 시퀀스 생성 중...\n",
      "\n",
      "유저 수: 2,000\n",
      "시퀀스 길이 - min: 19, max: 100, mean: 68.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_1/_b2j1k9j665dmn902xbrr8h40000gn/T/ipykernel_9569/242737090.py:22: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: list(zip(x['movieId'].tolist(), x['rating'].tolist())))\n"
     ]
    }
   ],
   "source": [
    "# 임베딩이 있는 영화만 필터링\n",
    "valid_movies = set(movie_ids)\n",
    "ratings_filtered = ratings[ratings['movieId'].isin(valid_movies)].copy()\n",
    "print(f\"필터링 후 평점 수: {len(ratings_filtered):,}\")\n",
    "\n",
    "# ========================================\n",
    "# 빠른 테스트를 위한 유저 샘플링\n",
    "# ========================================\n",
    "SAMPLE_USERS = 2000  # 빠른 테스트용\n",
    "\n",
    "if SAMPLE_USERS is not None:\n",
    "    sampled_user_ids = ratings_filtered['userId'].drop_duplicates().sample(n=SAMPLE_USERS, random_state=42)\n",
    "    ratings_filtered = ratings_filtered[ratings_filtered['userId'].isin(sampled_user_ids)]\n",
    "    print(f\"샘플링 후 평점 수: {len(ratings_filtered):,} ({SAMPLE_USERS:,} 유저)\")\n",
    "\n",
    "# 유저별로 시청 시퀀스 생성 (timestamp 순서, rating 포함)\n",
    "print(\"유저별 시퀀스 생성 중...\")\n",
    "user_sequences = (\n",
    "    ratings_filtered\n",
    "    .sort_values(['userId', 'timestamp'])\n",
    "    .groupby('userId')\n",
    "    .apply(lambda x: list(zip(x['movieId'].tolist(), x['rating'].tolist())))\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# 시퀀스 길이 통계\n",
    "seq_lengths = [len(seq) for seq in user_sequences.values()]\n",
    "print(f\"\\n유저 수: {len(user_sequences):,}\")\n",
    "print(f\"시퀀스 길이 - min: {min(seq_lengths)}, max: {max(seq_lengths)}, mean: {np.mean(seq_lengths):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 10,000\n",
      "Val samples: 2,000\n",
      "Test samples: 2,000\n",
      "\n",
      "Train rating 분포: mean=3.70, std=1.05\n"
     ]
    }
   ],
   "source": [
    "# Train/Val/Test 분할\n",
    "# 각 유저의 시청 이력에서 마지막 영화의 rating을 예측\n",
    "\n",
    "MIN_SEQ_LEN = 10  # 최소 시퀀스 길이 (history로 사용할 최소 개수)\n",
    "MAX_SEQ_LEN = 30  # 최대 시퀀스 길이\n",
    "MAX_SAMPLES_PER_USER = 5  # 유저당 최대 샘플 수 (빠른 테스트용)\n",
    "\n",
    "train_data = []\n",
    "val_data = []\n",
    "test_data = []\n",
    "\n",
    "for user_id, seq in user_sequences.items():\n",
    "    if len(seq) < MIN_SEQ_LEN + 1:\n",
    "        continue\n",
    "    \n",
    "    # Test: 마지막 영화 rating 예측\n",
    "    history = seq[:-1][-MAX_SEQ_LEN:]  # (movieId, rating) 튜플 리스트\n",
    "    target_movie, target_rating = seq[-1]\n",
    "    test_data.append((user_id, history, target_movie, target_rating))\n",
    "    \n",
    "    # Val: 마지막-1 영화 rating 예측\n",
    "    if len(seq) >= MIN_SEQ_LEN + 2:\n",
    "        history = seq[:-2][-MAX_SEQ_LEN:]\n",
    "        target_movie, target_rating = seq[-2]\n",
    "        val_data.append((user_id, history, target_movie, target_rating))\n",
    "    \n",
    "    # Train: 나머지 위치에서 샘플링\n",
    "    train_positions = list(range(MIN_SEQ_LEN, len(seq) - 2))\n",
    "    if len(train_positions) > MAX_SAMPLES_PER_USER:\n",
    "        step = len(train_positions) // MAX_SAMPLES_PER_USER\n",
    "        train_positions = train_positions[::step][:MAX_SAMPLES_PER_USER]\n",
    "    \n",
    "    for i in train_positions:\n",
    "        history = seq[:i][-MAX_SEQ_LEN:]\n",
    "        target_movie, target_rating = seq[i]\n",
    "        train_data.append((user_id, history, target_movie, target_rating))\n",
    "\n",
    "print(f\"Train samples: {len(train_data):,}\")\n",
    "print(f\"Val samples: {len(val_data):,}\")\n",
    "print(f\"Test samples: {len(test_data):,}\")\n",
    "\n",
    "# Rating 분포 확인\n",
    "train_ratings = [d[3] for d in train_data]\n",
    "print(f\"\\nTrain rating 분포: mean={np.mean(train_ratings):.2f}, std={np.std(train_ratings):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingDataset(Dataset):\n",
    "    def __init__(self, data, movie_to_idx, embeddings, max_len=30):\n",
    "        \"\"\"\n",
    "        data: list of (user_id, history, target_movie_id, target_rating)\n",
    "        history: list of (movieId, rating) tuples\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.movie_to_idx = movie_to_idx\n",
    "        self.embeddings = torch.from_numpy(embeddings)\n",
    "        self.max_len = max_len\n",
    "        self.emb_dim = embeddings.shape[1]\n",
    "        \n",
    "        # Rating 정규화 파라미터 (1-5 → 0-1)\n",
    "        self.rating_min = 0.5\n",
    "        self.rating_max = 5.0\n",
    "    \n",
    "    def normalize_rating(self, rating):\n",
    "        \"\"\"Rating을 0-1 범위로 정규화\"\"\"\n",
    "        return (rating - self.rating_min) / (self.rating_max - self.rating_min)\n",
    "    \n",
    "    def denormalize_rating(self, rating):\n",
    "        \"\"\"정규화된 rating을 원래 범위로 복원\"\"\"\n",
    "        return rating * (self.rating_max - self.rating_min) + self.rating_min\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        user_id, history, target_movie, target_rating = self.data[idx]\n",
    "        \n",
    "        # History 임베딩 및 rating\n",
    "        hist_idx = [self.movie_to_idx[mid] for mid, _ in history]\n",
    "        hist_ratings = [self.normalize_rating(r) for _, r in history]  # 정규화\n",
    "        \n",
    "        hist_emb = self.embeddings[hist_idx]  # (seq_len, emb_dim)\n",
    "        hist_ratings = torch.tensor(hist_ratings, dtype=torch.float32)  # (seq_len,)\n",
    "        \n",
    "        # Target\n",
    "        target_idx = self.movie_to_idx[target_movie]\n",
    "        target_emb = self.embeddings[target_idx]  # (emb_dim,)\n",
    "        target_rating_norm = self.normalize_rating(target_rating)  # 정규화\n",
    "        target_rating_tensor = torch.tensor(target_rating_norm, dtype=torch.float32)\n",
    "        \n",
    "        # 패딩 (앞에서부터)\n",
    "        seq_len = len(hist_idx)\n",
    "        if seq_len < self.max_len:\n",
    "            pad_len = self.max_len - seq_len\n",
    "            hist_emb = torch.cat([torch.zeros(pad_len, self.emb_dim), hist_emb], dim=0)\n",
    "            hist_ratings = torch.cat([torch.zeros(pad_len), hist_ratings], dim=0)\n",
    "            mask = torch.cat([torch.zeros(pad_len), torch.ones(seq_len)])\n",
    "        else:\n",
    "            hist_emb = hist_emb[-self.max_len:]\n",
    "            hist_ratings = hist_ratings[-self.max_len:]\n",
    "            mask = torch.ones(self.max_len)\n",
    "        \n",
    "        return {\n",
    "            'hist_emb': hist_emb,           # (max_len, emb_dim)\n",
    "            'hist_ratings': hist_ratings,   # (max_len,) - 정규화됨\n",
    "            'mask': mask,                   # (max_len,)\n",
    "            'target_emb': target_emb,       # (emb_dim,)\n",
    "            'target_rating': target_rating_tensor, # scalar - 정규화됨\n",
    "            'target_rating_orig': torch.tensor(target_rating, dtype=torch.float32),  # 원본\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 79\n",
      "Val batches: 16\n",
      "Test batches: 16\n",
      "\n",
      "Sample shapes:\n",
      "  hist_emb: torch.Size([30, 300])\n",
      "  hist_ratings: torch.Size([30])\n",
      "  mask: torch.Size([30])\n",
      "  target_emb: torch.Size([300])\n",
      "  target_rating: torch.Size([])\n",
      "  target_rating_orig: torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 생성\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_dataset = RatingDataset(train_data, movie_to_idx, embeddings_norm, MAX_SEQ_LEN)\n",
    "val_dataset = RatingDataset(val_data, movie_to_idx, embeddings_norm, MAX_SEQ_LEN)\n",
    "test_dataset = RatingDataset(test_data, movie_to_idx, embeddings_norm, MAX_SEQ_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "\n",
    "# 샘플 확인\n",
    "sample = train_dataset[0]\n",
    "print(f\"\\nSample shapes:\")\n",
    "for k, v in sample.items():\n",
    "    print(f\"  {k}: {v.shape if hasattr(v, 'shape') else v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Rating Predictor 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=100):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    간단하고 효과적인 Rating 예측 모델\n",
    "    \n",
    "    핵심 아이디어:\n",
    "    1. Target 영화와 History 영화들 간의 유사도 계산\n",
    "    2. 유사도 기반 가중 평균 + 학습 가능한 bias\n",
    "    3. 유저의 평균 rating 경향 반영\n",
    "    \"\"\"\n",
    "    def __init__(self, emb_dim=300, hidden_dim=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb_dim = emb_dim\n",
    "        \n",
    "        # 유사도 계산을 위한 projection\n",
    "        self.query_proj = nn.Linear(emb_dim, hidden_dim)\n",
    "        self.key_proj = nn.Linear(emb_dim, hidden_dim)\n",
    "        \n",
    "        # Rating과 결합하는 layer\n",
    "        self.rating_encoder = nn.Sequential(\n",
    "            nn.Linear(1, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "        )\n",
    "        \n",
    "        # Value projection (embedding + rating 정보)\n",
    "        self.value_proj = nn.Linear(emb_dim + hidden_dim, hidden_dim)\n",
    "        \n",
    "        # 최종 rating 예측\n",
    "        self.output_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim + hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid(),  # 0-1 범위 출력\n",
    "        )\n",
    "        \n",
    "        # 유저 평균 rating 예측용 (bias term)\n",
    "        self.user_bias = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "        self.scale = hidden_dim ** 0.5\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, hist_emb, hist_ratings, mask, target_emb):\n",
    "        \"\"\"\n",
    "        hist_emb: (batch, seq_len, emb_dim)\n",
    "        hist_ratings: (batch, seq_len) - 정규화된 rating (0-1)\n",
    "        mask: (batch, seq_len)\n",
    "        target_emb: (batch, emb_dim)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = hist_emb.shape\n",
    "        \n",
    "        # Query: target 영화\n",
    "        query = self.query_proj(target_emb)  # (batch, hidden_dim)\n",
    "        \n",
    "        # Key: history 영화들\n",
    "        key = self.key_proj(hist_emb)  # (batch, seq_len, hidden_dim)\n",
    "        \n",
    "        # Attention score (유사도)\n",
    "        attn_scores = torch.bmm(key, query.unsqueeze(-1)).squeeze(-1)  # (batch, seq_len)\n",
    "        attn_scores = attn_scores / self.scale\n",
    "        \n",
    "        # Mask 적용\n",
    "        attn_scores = attn_scores.masked_fill(mask == 0, float('-inf'))\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)  # (batch, seq_len)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        # Rating 정보 인코딩\n",
    "        rating_encoded = self.rating_encoder(hist_ratings.unsqueeze(-1))  # (batch, seq_len, hidden_dim)\n",
    "        \n",
    "        # Value: embedding + rating 정보\n",
    "        value_input = torch.cat([hist_emb, rating_encoded], dim=-1)  # (batch, seq_len, emb_dim + hidden_dim)\n",
    "        value = self.value_proj(value_input)  # (batch, seq_len, hidden_dim)\n",
    "        \n",
    "        # Attention-weighted sum\n",
    "        context = torch.bmm(attn_weights.unsqueeze(1), value).squeeze(1)  # (batch, hidden_dim)\n",
    "        \n",
    "        # 유저 평균 rating (history ratings의 가중 평균)\n",
    "        user_avg = torch.bmm(attn_weights.unsqueeze(1), rating_encoded).squeeze(1)  # (batch, hidden_dim)\n",
    "        user_bias = self.user_bias(user_avg).squeeze(-1)  # (batch,)\n",
    "        \n",
    "        # 최종 예측: context + target query 결합\n",
    "        combined = torch.cat([context, query], dim=-1)  # (batch, hidden_dim * 2)\n",
    "        pred = self.output_head(combined).squeeze(-1)  # (batch,)\n",
    "        \n",
    "        # User bias와 결합 (가중 평균)\n",
    "        final_pred = 0.7 * pred + 0.3 * user_bias\n",
    "        \n",
    "        return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 181,762\n",
      "RatingPredictor(\n",
      "  (query_proj): Linear(in_features=300, out_features=128, bias=True)\n",
      "  (key_proj): Linear(in_features=300, out_features=128, bias=True)\n",
      "  (rating_encoder): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=128, bias=True)\n",
      "  )\n",
      "  (value_proj): Linear(in_features=428, out_features=128, bias=True)\n",
      "  (output_head): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=64, out_features=1, bias=True)\n",
      "    (6): Sigmoid()\n",
      "  )\n",
      "  (user_bias): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = RatingPredictor(\n",
    "    emb_dim=emb_dim,\n",
    "    hidden_dim=128,\n",
    "    dropout=0.1,\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss & Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)  # lr 증가\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=1e-5)\n",
    "\n",
    "# Rating 역정규화 함수\n",
    "def denormalize_rating(rating, rating_min=0.5, rating_max=5.0):\n",
    "    return rating * (rating_max - rating_min) + rating_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, device):\n",
    "    \"\"\"RMSE, MAE 계산 (원본 rating 스케일)\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            hist_emb = batch['hist_emb'].to(device)\n",
    "            hist_ratings = batch['hist_ratings'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "            target_emb = batch['target_emb'].to(device)\n",
    "            target_rating = batch['target_rating'].to(device)  # 정규화된 값\n",
    "            target_rating_orig = batch['target_rating_orig'].to(device)  # 원본 값\n",
    "            \n",
    "            pred = model(hist_emb, hist_ratings, mask, target_emb)  # 정규화된 예측\n",
    "            \n",
    "            loss = criterion(pred, target_rating)\n",
    "            total_loss += loss.item() * len(target_rating)\n",
    "            total_samples += len(target_rating)\n",
    "            \n",
    "            # 역정규화하여 원본 스케일로 변환\n",
    "            pred_orig = denormalize_rating(pred.cpu().numpy())\n",
    "            all_preds.extend(pred_orig)\n",
    "            all_targets.extend(target_rating_orig.cpu().numpy())\n",
    "    \n",
    "    preds = np.array(all_preds)\n",
    "    targets = np.array(all_targets)\n",
    "    \n",
    "    mse = np.mean((preds - targets) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(preds - targets))\n",
    "    \n",
    "    return {\n",
    "        'MSE': mse, \n",
    "        'RMSE': rmse, \n",
    "        'MAE': mae, \n",
    "        'loss': total_loss / total_samples,  # 정규화된 loss\n",
    "        'preds': all_preds, \n",
    "        'targets': all_targets\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30:  32%|███▏      | 25/79 [00:01<00:02, 26.24it/s, loss=0.0625]"
     ]
    }
   ],
   "source": [
    "# 학습 루프\n",
    "N_EPOCHS = 30\n",
    "best_rmse = float('inf')\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_rmse': [], 'val_rmse': [], 'val_mae': []}\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_preds = []\n",
    "    train_targets = []\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{N_EPOCHS}')\n",
    "    for batch in pbar:\n",
    "        hist_emb = batch['hist_emb'].to(device)\n",
    "        hist_ratings = batch['hist_ratings'].to(device)\n",
    "        mask = batch['mask'].to(device)\n",
    "        target_emb = batch['target_emb'].to(device)\n",
    "        target_rating = batch['target_rating'].to(device)  # 정규화된 값\n",
    "        target_rating_orig = batch['target_rating_orig']  # 원본\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = model(hist_emb, hist_ratings, mask, target_emb)\n",
    "        loss = criterion(pred, target_rating)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # 원본 스케일로 변환하여 저장\n",
    "        pred_orig = denormalize_rating(pred.detach().cpu().numpy())\n",
    "        train_preds.extend(pred_orig)\n",
    "        train_targets.extend(target_rating_orig.numpy())\n",
    "        \n",
    "        pbar.set_postfix(loss=f'{loss.item():.4f}')\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_rmse = np.sqrt(np.mean((np.array(train_preds) - np.array(train_targets)) ** 2))\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Validation\n",
    "    val_results = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_results['loss'])\n",
    "    history['train_rmse'].append(train_rmse)\n",
    "    history['val_rmse'].append(val_results['RMSE'])\n",
    "    history['val_mae'].append(val_results['MAE'])\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Train RMSE={train_rmse:.4f}, Val RMSE={val_results['RMSE']:.4f}, Val MAE={val_results['MAE']:.4f}\")\n",
    "    \n",
    "    # Best model 저장\n",
    "    if val_results['RMSE'] < best_rmse:\n",
    "        best_rmse = val_results['RMSE']\n",
    "        torch.save(model.state_dict(), PROCESSED.DIR / 'rating_predictor_best.pt')\n",
    "        print(f\"  -> Best model saved! (RMSE={best_rmse:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 곡선 시각화\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# 1. Loss (MSE)\n",
    "axes[0].plot(range(1, len(history['train_loss'])+1), history['train_loss'], marker='o', label='Train', color='blue')\n",
    "axes[0].plot(range(1, len(history['val_loss'])+1), history['val_loss'], marker='s', label='Val', color='red')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('MSE Loss')\n",
    "axes[0].set_title('Training & Validation Loss (MSE)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. RMSE\n",
    "axes[1].plot(range(1, len(history['train_rmse'])+1), history['train_rmse'], marker='o', label='Train', color='blue')\n",
    "axes[1].plot(range(1, len(history['val_rmse'])+1), history['val_rmse'], marker='s', label='Val', color='red')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('RMSE')\n",
    "axes[1].set_title('Training & Validation RMSE')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. MAE\n",
    "axes[2].plot(range(1, len(history['val_mae'])+1), history['val_mae'], marker='s', color='green')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('MAE')\n",
    "axes[2].set_title('Validation MAE')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 최종 결과 출력\n",
    "print(\"\\n[학습 결과 요약]\")\n",
    "print(f\"  최종 Train RMSE: {history['train_rmse'][-1]:.4f}\")\n",
    "print(f\"  최종 Val RMSE:   {history['val_rmse'][-1]:.4f}\")\n",
    "print(f\"  최종 Val MAE:    {history['val_mae'][-1]:.4f}\")\n",
    "print(f\"  Best Val RMSE:   {best_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 테스트 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model 로드\n",
    "model.load_state_dict(torch.load(PROCESSED.DIR / 'rating_predictor_best.pt', weights_only=True))\n",
    "\n",
    "# Test 평가\n",
    "test_results = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Test Results\")\n",
    "print(\"=\"*50)\n",
    "print(f\"  RMSE: {test_results['RMSE']:.4f}\")\n",
    "print(f\"  MAE:  {test_results['MAE']:.4f}\")\n",
    "print(f\"  MSE:  {test_results['MSE']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 vs 실제 시각화\n",
    "preds = np.array(test_results['preds'])\n",
    "targets = np.array(test_results['targets'])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# 1. Scatter plot\n",
    "axes[0].scatter(targets, preds, alpha=0.3, s=10)\n",
    "axes[0].plot([0.5, 5.5], [0.5, 5.5], 'r--', label='Perfect prediction')\n",
    "axes[0].set_xlabel('Actual Rating')\n",
    "axes[0].set_ylabel('Predicted Rating')\n",
    "axes[0].set_title('Predicted vs Actual Ratings')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xlim(0.5, 5.5)\n",
    "axes[0].set_ylim(0.5, 5.5)\n",
    "\n",
    "# 2. Error distribution\n",
    "errors = preds - targets\n",
    "axes[1].hist(errors, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=0, color='r', linestyle='--', label='Zero error')\n",
    "axes[1].set_xlabel('Prediction Error (Pred - Actual)')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title(f'Error Distribution (mean={np.mean(errors):.3f}, std={np.std(errors):.3f})')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Baseline 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline 1: 유저 평균 rating\n",
    "def evaluate_baseline_user_mean(test_data, train_data):\n",
    "    \"\"\"유저의 평균 평점을 예측값으로 사용\"\"\"\n",
    "    # 유저별 평균 rating 계산 (train 데이터 기반)\n",
    "    user_ratings = {}\n",
    "    for user_id, history, _, _ in train_data:\n",
    "        if user_id not in user_ratings:\n",
    "            user_ratings[user_id] = []\n",
    "        user_ratings[user_id].extend([r for _, r in history])\n",
    "    \n",
    "    user_mean = {uid: np.mean(ratings) for uid, ratings in user_ratings.items()}\n",
    "    global_mean = np.mean([r for ratings in user_ratings.values() for r in ratings])\n",
    "    \n",
    "    preds = []\n",
    "    targets = []\n",
    "    for user_id, _, _, target_rating in test_data:\n",
    "        pred = user_mean.get(user_id, global_mean)\n",
    "        preds.append(pred)\n",
    "        targets.append(target_rating)\n",
    "    \n",
    "    preds = np.array(preds)\n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    rmse = np.sqrt(np.mean((preds - targets) ** 2))\n",
    "    mae = np.mean(np.abs(preds - targets))\n",
    "    \n",
    "    return {'RMSE': rmse, 'MAE': mae}\n",
    "\n",
    "# Baseline 2: 전체 평균 rating\n",
    "def evaluate_baseline_global_mean(test_data, train_data):\n",
    "    \"\"\"전체 평균 평점을 예측값으로 사용\"\"\"\n",
    "    all_ratings = []\n",
    "    for _, history, _, _ in train_data:\n",
    "        all_ratings.extend([r for _, r in history])\n",
    "    \n",
    "    global_mean = np.mean(all_ratings)\n",
    "    \n",
    "    targets = [r for _, _, _, r in test_data]\n",
    "    preds = [global_mean] * len(targets)\n",
    "    \n",
    "    preds = np.array(preds)\n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    rmse = np.sqrt(np.mean((preds - targets) ** 2))\n",
    "    mae = np.mean(np.abs(preds - targets))\n",
    "    \n",
    "    return {'RMSE': rmse, 'MAE': mae}\n",
    "\n",
    "# Baseline 3: 최근 rating 평균\n",
    "def evaluate_baseline_recent_mean(test_data, k=5):\n",
    "    \"\"\"최근 k개 영화의 평균 평점을 예측값으로 사용\"\"\"\n",
    "    preds = []\n",
    "    targets = []\n",
    "    \n",
    "    for _, history, _, target_rating in test_data:\n",
    "        recent_ratings = [r for _, r in history[-k:]]\n",
    "        pred = np.mean(recent_ratings) if recent_ratings else 3.0\n",
    "        preds.append(pred)\n",
    "        targets.append(target_rating)\n",
    "    \n",
    "    preds = np.array(preds)\n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    rmse = np.sqrt(np.mean((preds - targets) ** 2))\n",
    "    mae = np.mean(np.abs(preds - targets))\n",
    "    \n",
    "    return {'RMSE': rmse, 'MAE': mae}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline 평가\n",
    "baseline_global = evaluate_baseline_global_mean(test_data, train_data)\n",
    "baseline_user = evaluate_baseline_user_mean(test_data, train_data)\n",
    "baseline_recent = evaluate_baseline_recent_mean(test_data, k=5)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Baseline vs Transformer 비교\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Method':<25} {'RMSE':>12} {'MAE':>12}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Global Mean':<25} {baseline_global['RMSE']:>12.4f} {baseline_global['MAE']:>12.4f}\")\n",
    "print(f\"{'User Mean':<25} {baseline_user['RMSE']:>12.4f} {baseline_user['MAE']:>12.4f}\")\n",
    "print(f\"{'Recent-5 Mean':<25} {baseline_recent['RMSE']:>12.4f} {baseline_recent['MAE']:>12.4f}\")\n",
    "print(f\"{'Transformer (Ours)':<25} {test_results['RMSE']:>12.4f} {test_results['MAE']:>12.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 개선율\n",
    "improvement = (baseline_user['RMSE'] - test_results['RMSE']) / baseline_user['RMSE'] * 100\n",
    "print(f\"\\nUser Mean 대비 RMSE 개선율: {improvement:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비교 시각화\n",
    "methods = ['Global Mean', 'User Mean', 'Recent-5', 'Transformer']\n",
    "rmse_values = [baseline_global['RMSE'], baseline_user['RMSE'], baseline_recent['RMSE'], test_results['RMSE']]\n",
    "mae_values = [baseline_global['MAE'], baseline_user['MAE'], baseline_recent['MAE'], test_results['MAE']]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(methods))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, rmse_values, width, label='RMSE', color='steelblue')\n",
    "bars2 = ax.bar(x + width/2, mae_values, width, label='MAE', color='coral')\n",
    "\n",
    "# 값 표시\n",
    "for bar in bars1:\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "            f'{bar.get_height():.3f}', ha='center', va='bottom', fontsize=10)\n",
    "for bar in bars2:\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "            f'{bar.get_height():.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "ax.set_ylabel('Error')\n",
    "ax.set_title('Rating 예측 성능 비교')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(methods)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 예측 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카탈로그 로드\n",
    "catalog = pd.read_parquet(PROCESSED.MOVIE_CATALOG_PARQUET)\n",
    "movie_titles = catalog.set_index('movieId')['original_title'].to_dict()\n",
    "\n",
    "def get_movie_title(movie_id):\n",
    "    return movie_titles.get(movie_id, f'Unknown ({movie_id})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 예시\n",
    "model.eval()\n",
    "\n",
    "for i in [0, 100, 500]:\n",
    "    if i >= len(test_data):\n",
    "        continue\n",
    "    \n",
    "    user_id, history, target_movie, target_rating = test_data[i]\n",
    "    \n",
    "    # 모델 예측\n",
    "    sample = test_dataset[i]\n",
    "    with torch.no_grad():\n",
    "        pred_norm = model(\n",
    "            sample['hist_emb'].unsqueeze(0).to(device),\n",
    "            sample['hist_ratings'].unsqueeze(0).to(device),\n",
    "            sample['mask'].unsqueeze(0).to(device),\n",
    "            sample['target_emb'].unsqueeze(0).to(device),\n",
    "        ).item()\n",
    "    \n",
    "    # 역정규화\n",
    "    pred = denormalize_rating(pred_norm)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(f\"[유저 {user_id}]\")\n",
    "    print(\"\\n최근 시청 이력 (최근 5개):\")\n",
    "    for mid, rating in history[-5:]:\n",
    "        title = get_movie_title(mid)[:40]\n",
    "        print(f\"  - {title}: ⭐{rating}\")\n",
    "    \n",
    "    print(f\"\\n타겟 영화: {get_movie_title(target_movie)}\")\n",
    "    print(f\"  실제 평점: ⭐{target_rating}\")\n",
    "    print(f\"  예측 평점: ⭐{pred:.2f}\")\n",
    "    print(f\"  오차: {abs(pred - target_rating):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 모델 저장\n",
    "save_path = PROCESSED.DIR / 'rating_predictor_final.pt'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': {\n",
    "        'emb_dim': emb_dim,\n",
    "        'hidden_dim': 128,\n",
    "        'max_len': MAX_SEQ_LEN,\n",
    "    },\n",
    "    'test_results': {\n",
    "        'RMSE': test_results['RMSE'],\n",
    "        'MAE': test_results['MAE'],\n",
    "    },\n",
    "    'history': history,\n",
    "}, save_path)\n",
    "\n",
    "print(f\"모델 저장: {save_path}\")\n",
    "print(f\"\\n최종 Test 성능:\")\n",
    "print(f\"  RMSE: {test_results['RMSE']:.4f}\")\n",
    "print(f\"  MAE:  {test_results['MAE']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
