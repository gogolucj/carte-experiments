{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71738,
     "status": "ok",
     "timestamp": 1767275217505,
     "user": {
      "displayName": "J K",
      "userId": "02403182054655897372"
     },
     "user_tz": -540
    },
    "id": "51JJOcnr23TN",
    "outputId": "21303db7-3ce4-4d29-835c-14dc207579e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.11.12)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
      "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.7.0\n",
      "Collecting carte_ai\n",
      "  Downloading carte_ai-0.0.26-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from carte_ai) (2.0.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from carte_ai) (2.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from carte_ai) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from carte_ai) (1.6.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from carte_ai) (2.9.0+cu126)\n",
      "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (from carte_ai) (2.7.0)\n",
      "Collecting torcheval (from carte_ai)\n",
      "  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting fasttext (from carte_ai)\n",
      "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting category-encoders (from carte_ai)\n",
      "  Downloading category_encoders-2.9.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting tabpfn (from carte_ai)\n",
      "  Downloading tabpfn-6.2.0-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (from carte_ai) (3.1.2)\n",
      "Collecting catboost (from carte_ai)\n",
      "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from carte_ai) (0.13.2)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from carte_ai) (18.1.0)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost->carte_ai) (0.21)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost->carte_ai) (3.10.0)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost->carte_ai) (5.24.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost->carte_ai) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->carte_ai) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->carte_ai) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->carte_ai) (2025.3)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from category-encoders->carte_ai) (1.0.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from category-encoders->carte_ai) (0.14.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->carte_ai) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->carte_ai) (3.6.0)\n",
      "Collecting pybind11>=2.2 (from fasttext->carte_ai)\n",
      "  Using cached pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from fasttext->carte_ai) (75.2.0)\n",
      "Requirement already satisfied: typing_extensions>=4.12.0 in /usr/local/lib/python3.12/dist-packages (from tabpfn->carte_ai) (4.15.0)\n",
      "Requirement already satisfied: einops<0.9,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from tabpfn->carte_ai) (0.8.1)\n",
      "Requirement already satisfied: huggingface-hub<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from tabpfn->carte_ai) (0.36.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from tabpfn->carte_ai) (2.12.3)\n",
      "Requirement already satisfied: pydantic-settings>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from tabpfn->carte_ai) (2.12.0)\n",
      "Collecting eval-type-backport>=0.2.2 (from tabpfn->carte_ai)\n",
      "  Downloading eval_type_backport-0.3.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tabpfn-common-utils>=0.2.8 (from tabpfn-common-utils[telemetry-interactive]>=0.2.8->tabpfn->carte_ai)\n",
      "  Downloading tabpfn_common_utils-0.2.13-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->carte_ai) (3.20.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->carte_ai) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->carte_ai) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->carte_ai) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->carte_ai) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->carte_ai) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->carte_ai) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->carte_ai) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->carte_ai) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->carte_ai) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->carte_ai) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->carte_ai) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->carte_ai) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->carte_ai) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->carte_ai) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->carte_ai) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->carte_ai) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->carte_ai) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->carte_ai) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->carte_ai) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->carte_ai) (3.5.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric->carte_ai) (3.13.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric->carte_ai) (5.9.5)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric->carte_ai) (3.2.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric->carte_ai) (2.32.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric->carte_ai) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric->carte_ai) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2,>=0.19.0->tabpfn->carte_ai) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2,>=0.19.0->tabpfn->carte_ai) (6.0.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2,>=0.19.0->tabpfn->carte_ai) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost->carte_ai) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost->carte_ai) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost->carte_ai) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost->carte_ai) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost->carte_ai) (11.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->tabpfn->carte_ai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->tabpfn->carte_ai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->tabpfn->carte_ai) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.10.1->tabpfn->carte_ai) (1.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->carte_ai) (1.3.0)\n",
      "Requirement already satisfied: platformdirs>=4 in /usr/local/lib/python3.12/dist-packages (from tabpfn-common-utils>=0.2.8->tabpfn-common-utils[telemetry-interactive]>=0.2.8->tabpfn->carte_ai) (4.5.1)\n",
      "Collecting posthog~=6.7 (from tabpfn-common-utils>=0.2.8->tabpfn-common-utils[telemetry-interactive]>=0.2.8->tabpfn->carte_ai)\n",
      "  Downloading posthog-6.9.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting requests (from torch-geometric->carte_ai)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: ruff>=0.11.6 in /usr/local/lib/python3.12/dist-packages (from tabpfn-common-utils>=0.2.8->tabpfn-common-utils[telemetry-interactive]>=0.2.8->tabpfn->carte_ai) (0.14.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric->carte_ai) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric->carte_ai) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric->carte_ai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric->carte_ai) (2025.11.12)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric->carte_ai) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric->carte_ai) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric->carte_ai) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric->carte_ai) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric->carte_ai) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric->carte_ai) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric->carte_ai) (1.22.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->carte_ai) (3.0.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost->carte_ai) (9.1.2)\n",
      "Collecting backoff>=1.10.0 (from posthog~=6.7->tabpfn-common-utils>=0.2.8->tabpfn-common-utils[telemetry-interactive]>=0.2.8->tabpfn->carte_ai)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog~=6.7->tabpfn-common-utils>=0.2.8->tabpfn-common-utils[telemetry-interactive]>=0.2.8->tabpfn->carte_ai) (1.9.0)\n",
      "Downloading carte_ai-0.0.26-py3-none-any.whl (40.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading category_encoders-2.9.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.9/85.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tabpfn-6.2.0-py3-none-any.whl (553 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m554.0/554.0 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading eval_type_backport-0.3.1-py3-none-any.whl (6.1 kB)\n",
      "Using cached pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
      "Downloading tabpfn_common_utils-0.2.13-py3-none-any.whl (36 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading posthog-6.9.3-py3-none-any.whl (144 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fasttext: filename=fasttext-0.9.3-cp312-cp312-linux_x86_64.whl size=4498212 sha256=aefe07eb6c522e1674509b730b222f68832409d30b8070cfcdda03300e72fce2\n",
      "  Stored in directory: /root/.cache/pip/wheels/20/27/95/a7baf1b435f1cbde017cabdf1e9688526d2b0e929255a359c6\n",
      "Successfully built fasttext\n",
      "Installing collected packages: torcheval, requests, pybind11, eval-type-backport, backoff, posthog, fasttext, tabpfn-common-utils, catboost, category-encoders, tabpfn, carte_ai\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.4\n",
      "    Uninstalling requests-2.32.4:\n",
      "      Successfully uninstalled requests-2.32.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed backoff-2.2.1 carte_ai-0.0.26 catboost-1.2.8 category-encoders-2.9.0 eval-type-backport-0.3.1 fasttext-0.9.3 posthog-6.9.3 pybind11-3.0.1 requests-2.32.5 tabpfn-6.2.0 tabpfn-common-utils-0.2.13 torcheval-0.0.7\n",
      "Requirement already satisfied: fasttext in /usr/local/lib/python3.12/dist-packages (0.9.3)\n",
      "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.12/dist-packages (from fasttext) (3.0.1)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from fasttext) (75.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fasttext) (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install torch_geometric\n",
    "! pip install carte_ai\n",
    "! pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2794,
     "status": "ok",
     "timestamp": 1767277941885,
     "user": {
      "displayName": "J K",
      "userId": "02403182054655897372"
     },
     "user_tz": -540
    },
    "id": "KK1UhC_MybsZ",
    "outputId": "39607abf-340b-40a2-bd17-931b90ab3046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 113446,
     "status": "ok",
     "timestamp": 1767278057420,
     "user": {
      "displayName": "J K",
      "userId": "02403182054655897372"
     },
     "user_tz": -540
    },
    "id": "PcIdUkAtfoPr",
    "outputId": "b6d00487-7d68-4069-e1a5-daef38c09e3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IO] input=/content/drive/MyDrive/대학원/논문/CARTE/data/processed/movie_catalog_flat.parquet\n",
      "[IO] output=/content/drive/MyDrive/대학원/논문/CARTE/data/processed/movie_embeddings.parquet\n",
      "[IO] ckpt=/usr/local/lib/python3.12/dist-packages/carte_ai/data/etc/kg_pretrained.pt\n",
      "[TextSlot] produced_by_company_1 na_ratio=0.124\n",
      "[TextSlot] produced_in_country_1 na_ratio=0.054\n",
      "[TextSlot] spoken_language_1 na_ratio=0.036\n",
      "[TextSlot] actor_1 na_ratio=0.037\n",
      "[TextSlot] actor_2 na_ratio=0.070\n",
      "[TextSlot] actor_3 na_ratio=0.089\n",
      "[TextSlot] director_1 na_ratio=0.006\n",
      "[TextSlot] writer_1 na_ratio=0.119\n",
      "[TextSlot] genre_1 na_ratio=0.009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:188: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:199: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Graphlets] count=86,272\n",
      "[Graphlets] sample0 x=(11, 300) edge_attr=(20, 300)\n",
      "[CKPT] path: /usr/local/lib/python3.12/dist-packages/carte_ai/data/etc/kg_pretrained.pt\n",
      "[CKPT] size: 38.35 MB\n",
      "[CKPT] type: <class 'dict'>\n",
      "[CKPT] top-level keys(sample): ['ft_base.initial_x.0.weight', 'ft_base.initial_x.0.bias', 'ft_base.initial_x.2.weight', 'ft_base.initial_x.2.bias', 'ft_base.initial_e.0.weight', 'ft_base.initial_e.0.bias', 'ft_base.initial_e.2.weight', 'ft_base.initial_e.2.bias', 'ft_base.layers.0.g_attn.lin_query.weight', 'ft_base.layers.0.g_attn.lin_key.weight', 'ft_base.layers.0.g_attn.lin_value.weight', 'ft_base.layers.0.g_attn.lin_edge.weight', 'ft_base.layers.0.g_attn.lin_edge.bias', 'ft_base.layers.0.linear_net_x.0.weight', 'ft_base.layers.0.linear_net_x.0.bias', 'ft_base.layers.0.linear_net_x.3.weight', 'ft_base.layers.0.linear_net_x.3.bias', 'ft_base.layers.0.norm1_x.weight', 'ft_base.layers.0.norm1_x.bias', 'ft_base.layers.0.norm2_x.weight', 'ft_base.layers.0.norm2_x.bias', 'ft_base.layers.0.linear_net_e.0.weight', 'ft_base.layers.0.linear_net_e.0.bias', 'ft_base.layers.0.linear_net_e.3.weight', 'ft_base.layers.0.linear_net_e.3.bias', 'ft_base.layers.0.norm1_e.weight', 'ft_base.layers.0.norm1_e.bias', 'ft_base.layers.1.g_attn.lin_query.weight', 'ft_base.layers.1.g_attn.lin_key.weight', 'ft_base.layers.1.g_attn.lin_value.weight']\n",
      "[CKPT] contains pretrain_classifier.* = True\n",
      "[Verify] common_keys=19 / model_keys=19 / ckpt_keys=251\n",
      "[Verify] initial_x.0.weight allclose=True shape=(300, 300)\n",
      "[Verify] initial_e.0.weight allclose=True shape=(300, 300)\n",
      "[Verify] read_out_block.g_attn.lin_query.weight allclose=True shape=(300, 300)\n",
      "[Verify] read_out_block.g_attn.lin_key.weight allclose=True shape=(300, 300)\n",
      "[Verify] read_out_block.g_attn.lin_value.weight allclose=True shape=(300, 300)\n",
      "[Verify] injected=True (matched 5/5)\n",
      "[Model] input_dim_x=300 input_dim_e=300 hidden_dim=300 ff_dim=300 heads=12\n",
      "[Model] num_layers=0 (ckpt_layers≈12) | 실제 MP≈1(readout 포함)\n",
      "[LoadState] missing_keys=0 unexpected_keys=232\n",
      "  - missing sample: []\n",
      "  - unexpected sample: ['pretrain_classifier.0.weight', 'pretrain_classifier.0.bias', 'pretrain_classifier.2.weight', 'pretrain_classifier.2.bias', 'layers.0.g_attn.lin_query.weight', 'layers.0.g_attn.lin_key.weight', 'layers.0.g_attn.lin_value.weight', 'layers.0.g_attn.lin_edge.weight', 'layers.0.g_attn.lin_edge.bias', 'layers.0.linear_net_x.0.weight', 'layers.0.linear_net_x.0.bias', 'layers.0.linear_net_x.3.weight', 'layers.0.linear_net_x.3.bias', 'layers.0.norm1_x.weight', 'layers.0.norm1_x.bias', 'layers.0.norm2_x.weight', 'layers.0.norm2_x.bias', 'layers.0.linear_net_e.0.weight', 'layers.0.linear_net_e.0.bias', 'layers.0.linear_net_e.3.weight']\n",
      "[OK] pretrained weights injected ✅\n",
      "[Embed] batch1 head_emb shape=(256, 300)\n",
      "[OK] saved: /content/drive/MyDrive/대학원/논문/CARTE/data/processed/movie_embeddings.parquet rows=86,272 dim=300 device=cuda num_layers=0\n",
      "saved: /content/drive/MyDrive/대학원/논문/CARTE/data/processed/movie_embeddings.parquet\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Mapping, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from huggingface_hub import hf_hub_download\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# ============================================================\n",
    "# (1) CARTE import\n",
    "# ============================================================\n",
    "from carte_ai import Table2GraphTransformer\n",
    "from carte_ai.src.carte_model import CARTE_Base\n",
    "from carte_ai.configs.directory import config_directory\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# (0) 실행 환경 판별\n",
    "# ============================================================\n",
    "def is_ipython_env() -> bool:\n",
    "    \"\"\"\n",
    "    - 목적\n",
    "      - Colab/Jupyter(IPython) 환경 여부 판별\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from IPython import get_ipython  # type: ignore\n",
    "\n",
    "        return get_ipython() is not None\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# (2) 설정(스키마/실행옵션) - 한 곳에서 관리\n",
    "# ============================================================\n",
    "@dataclass(frozen=True)\n",
    "class CatalogSchema:\n",
    "    \"\"\"\n",
    "    - 목적\n",
    "      - 입력 catalog 스키마 정의\n",
    "    - 포인트\n",
    "      - 멀티값은 join하지 않고 slot 컬럼 유지\n",
    "    \"\"\"\n",
    "\n",
    "    id_col: str = \"movieId\"\n",
    "    num_cols: Tuple[str, ...] = (\"release_year\",)\n",
    "    text_cols_slot: Tuple[str, ...] = (\n",
    "        # companies\n",
    "        \"produced_by_company_1\",\n",
    "        # \"produced_by_company_2\",\n",
    "        # countries\n",
    "        \"produced_in_country_1\",\n",
    "        # \"produced_in_country_2\",\n",
    "        # languages\n",
    "        \"spoken_language_1\",\n",
    "        # \"spoken_language_2\",\n",
    "        # actors\n",
    "        \"actor_1\",\n",
    "        \"actor_2\",\n",
    "        \"actor_3\",\n",
    "        # director / writer\n",
    "        \"director_1\",\n",
    "        \"writer_1\",\n",
    "        # genres\n",
    "        \"genre_1\",\n",
    "        # \"genre_2\",\n",
    "        # \"genre_3\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def required_cols(self) -> Tuple[str, ...]:\n",
    "        return (self.id_col, *self.num_cols, *self.text_cols_slot)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class RunConfig:\n",
    "    \"\"\"\n",
    "    - 목적\n",
    "      - 실행 파라미터 묶음\n",
    "    \"\"\"\n",
    "\n",
    "    input_path: Path\n",
    "    out_path: Path\n",
    "    pretrained_model_path: Path\n",
    "    batch_size: int = 256\n",
    "    device: str = \"cpu\"\n",
    "    num_layers: int = 1  # ✅ 주의: 실제 message passing = num_layers + 1(readout)\n",
    "    verbose: bool = True\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# (3) 문자열 정규화 (논문 정합: 결측은 None 유지)\n",
    "# ============================================================\n",
    "def normalize_text(v: Any) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    - 목적\n",
    "      - 문자열 정규화\n",
    "    - 규칙\n",
    "      - None / NaN / \"\" -> None\n",
    "      - 그 외 -> 공백 정리 + strip\n",
    "    \"\"\"\n",
    "    if v is None:\n",
    "        return None\n",
    "    if isinstance(v, float) and np.isnan(v):\n",
    "        return None\n",
    "\n",
    "    s = str(v)\n",
    "    s = re.sub(r\"\\s+\", \" \", s.strip())\n",
    "    return s if s else None\n",
    "\n",
    "\n",
    "def build_model_input_table(\n",
    "    df_raw: pd.DataFrame,\n",
    "    *,\n",
    "    schema: CatalogSchema,\n",
    "    verbose: bool,\n",
    ") -> Tuple[pd.DataFrame, np.ndarray]:\n",
    "    \"\"\"\n",
    "    - 목적\n",
    "      - raw catalog -> CARTE 입력용 X, movie_id 배열 생성\n",
    "    - 포인트\n",
    "      - 멀티값은 slot 컬럼 유지\n",
    "      - 결측은 None/NaN 유지 (leaf 미생성 유도)\n",
    "    \"\"\"\n",
    "    missing = [c for c in schema.required_cols if c not in df_raw.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"[SchemaError] missing columns: {missing}\")\n",
    "\n",
    "    df = df_raw.loc[:, list(schema.required_cols)].copy()\n",
    "\n",
    "    # - id 결측 제거\n",
    "    df = df.dropna(subset=[schema.id_col]).reset_index(drop=True)\n",
    "    movie_ids = df[schema.id_col].astype(int).to_numpy()\n",
    "\n",
    "    # - numeric: NaN 유지\n",
    "    for c in schema.num_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    # - text: None 유지\n",
    "    for c in schema.text_cols_slot:\n",
    "        df[c] = df[c].apply(normalize_text).astype(\"object\")\n",
    "        if verbose:\n",
    "            na_ratio = float(df[c].isna().mean())\n",
    "            print(f\"[TextSlot] {c} na_ratio={na_ratio:.3f}\")\n",
    "\n",
    "    X = df.loc[:, [*schema.num_cols, *schema.text_cols_slot]].copy()\n",
    "    return X, movie_ids\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# (4) 체크포인트 로딩 유틸\n",
    "# ============================================================\n",
    "def extract_state_dict(ckpt_obj: Any) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    - 목적\n",
    "      - 다양한 체크포인트 포맷에서 state_dict 추출\n",
    "    \"\"\"\n",
    "    # - lightning 등\n",
    "    if hasattr(ckpt_obj, \"state_dict\") and callable(getattr(ckpt_obj, \"state_dict\")):\n",
    "        return dict(ckpt_obj.state_dict())\n",
    "\n",
    "    if isinstance(ckpt_obj, Mapping):\n",
    "        for key in (\"state_dict\", \"model_state_dict\", \"model\", \"net\"):\n",
    "            if key in ckpt_obj and isinstance(ckpt_obj[key], Mapping):\n",
    "                return dict(ckpt_obj[key])\n",
    "\n",
    "        # - dict 자체가 state_dict인 경우(텐서 비율로 추정)\n",
    "        tensor_cnt = sum(isinstance(v, torch.Tensor) for v in ckpt_obj.values())\n",
    "        if tensor_cnt >= max(1, len(ckpt_obj) // 3):\n",
    "            return dict(ckpt_obj)\n",
    "\n",
    "    raise ValueError(\"checkpoint에서 state_dict를 찾지 못했습니다.\")\n",
    "\n",
    "\n",
    "def strip_common_prefixes(state: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    - 목적\n",
    "      - 로딩 실패를 유발하는 공통 prefix 제거\n",
    "    \"\"\"\n",
    "    prefixes = (\"model.\", \"module.\", \"ft_base.\")\n",
    "    out: Dict[str, torch.Tensor] = {}\n",
    "\n",
    "    for k, v in state.items():\n",
    "        nk = k\n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed = False\n",
    "            for p in prefixes:\n",
    "                if nk.startswith(p):\n",
    "                    nk = nk[len(p) :]\n",
    "                    changed = True\n",
    "        out[nk] = v\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def infer_int_from_weight(state: Dict[str, torch.Tensor], key: str, axis: int) -> int:\n",
    "    \"\"\"\n",
    "    - 목적\n",
    "      - 특정 weight 텐서 shape에서 정수값 추론\n",
    "    \"\"\"\n",
    "    w = state.get(key)\n",
    "    if not isinstance(w, torch.Tensor) or w.ndim != 2:\n",
    "        raise ValueError(f\"state_dict에서 {key}를 찾지 못했습니다.\")\n",
    "    return int(w.shape[axis])\n",
    "\n",
    "\n",
    "def infer_model_hparams_from_state(state: Dict[str, torch.Tensor]) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    - 목적\n",
    "      - 체크포인트에서 모델 하이퍼파라미터 자동 추론\n",
    "    - 추론 규칙\n",
    "      - hidden_dim, input_dim_x: initial_x.0.weight (hidden_dim, input_dim_x)\n",
    "      - ff_dim: layers.0.linear_net_x.0.weight (ff_dim, hidden_dim)\n",
    "    \"\"\"\n",
    "    hidden_dim = infer_int_from_weight(state, \"initial_x.0.weight\", axis=0)\n",
    "    input_dim_x = infer_int_from_weight(state, \"initial_x.0.weight\", axis=1)\n",
    "\n",
    "    # - ff_dim 추론(가능하면)\n",
    "    ff_dim_key = \"layers.0.linear_net_x.0.weight\"\n",
    "    ff_dim = hidden_dim\n",
    "    if ff_dim_key in state and isinstance(state[ff_dim_key], torch.Tensor) and state[ff_dim_key].ndim == 2:\n",
    "        ff_dim = int(state[ff_dim_key].shape[0])\n",
    "\n",
    "    return {\n",
    "        \"input_dim_x\": input_dim_x,\n",
    "        \"hidden_dim\": hidden_dim,\n",
    "        \"ff_dim\": ff_dim,\n",
    "    }\n",
    "\n",
    "\n",
    "def infer_ckpt_num_layers(state: Dict[str, torch.Tensor]) -> int:\n",
    "    \"\"\"\n",
    "    - 목적\n",
    "      - 체크포인트 내부 layers.N 개수 추정(로그용)\n",
    "    \"\"\"\n",
    "    pat = re.compile(r\"(?:^|\\.)layers\\.(\\d+)\\.\")\n",
    "    idxs: List[int] = []\n",
    "    for k in state.keys():\n",
    "        m = pat.search(k)\n",
    "        if m:\n",
    "            idxs.append(int(m.group(1)))\n",
    "    return (max(idxs) + 1) if idxs else 0\n",
    "\n",
    "\n",
    "def build_device(device: Optional[str]) -> str:\n",
    "    \"\"\"\n",
    "    - 목적\n",
    "      - device 자동 선택\n",
    "    \"\"\"\n",
    "    if device is None or str(device).strip() == \"\":\n",
    "        return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    return str(device).strip()\n",
    "\n",
    "\n",
    "def load_carte_base(\n",
    "    *,\n",
    "    pretrained_model_path: Path,\n",
    "    device: str,\n",
    "    num_layers: int,\n",
    "    verbose: bool,\n",
    ") -> CARTE_Base:\n",
    "    \"\"\"\n",
    "    - 목적\n",
    "      - pretrained CARTE_Base 로드 + \"프리트레인 가중치 사용 여부\"를 확실히 검증\n",
    "    - 검증 포인트(중요)\n",
    "      1) ckpt 파일 존재/형태/키 확인\n",
    "      2) load_state_dict 결과(missing/unexpected) 확인\n",
    "      3) ckpt_state vs model.state_dict 값(allclose) 비교로 '실제 주입' 확정\n",
    "    - 주의\n",
    "      - CARTE_Base는 read_out_block이 1개 추가로 존재\n",
    "      - 즉, 실제 message passing 단계는 (num_layers + 1)로 보는 게 안전\n",
    "    \"\"\"\n",
    "\n",
    "    # ============================================================\n",
    "    # (A) 체크포인트 로드 + 정체 확인\n",
    "    # ============================================================\n",
    "    ckpt_path = Path(pretrained_model_path)\n",
    "    if not ckpt_path.exists():\n",
    "        raise FileNotFoundError(f\"[CKPT] file not found: {ckpt_path}\")\n",
    "\n",
    "    ckpt_obj = torch.load(str(ckpt_path), map_location=\"cpu\")\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[CKPT] path: {ckpt_path}\")\n",
    "        print(f\"[CKPT] size: {ckpt_path.stat().st_size / (1024**2):.2f} MB\")\n",
    "        print(f\"[CKPT] type: {type(ckpt_obj)}\")\n",
    "        if isinstance(ckpt_obj, dict):\n",
    "            print(f\"[CKPT] top-level keys(sample): {list(ckpt_obj.keys())[:30]}\")\n",
    "\n",
    "    raw_state = extract_state_dict(ckpt_obj)\n",
    "    state = strip_common_prefixes(raw_state)\n",
    "\n",
    "    # - pretrain ckpt 여부(약한 힌트): pretrain_classifier 파라미터가 있으면 pretrain에서 온 경우가 많음\n",
    "    if verbose:\n",
    "        has_pretrain_head = any(k.startswith(\"pretrain_classifier.\") for k in state.keys())\n",
    "        print(f\"[CKPT] contains pretrain_classifier.* = {has_pretrain_head}\")\n",
    "\n",
    "    # ============================================================\n",
    "    # (B) 체크포인트로부터 모델 하이퍼파라미터 추론\n",
    "    # ============================================================\n",
    "    h = infer_model_hparams_from_state(state)\n",
    "    input_dim_x = h[\"input_dim_x\"]\n",
    "    hidden_dim = h[\"hidden_dim\"]\n",
    "    ff_dim = h[\"ff_dim\"]\n",
    "\n",
    "    # - edge 입력도 동일 차원으로 가정(Table2GraphTransformer fastText=300과 정합)\n",
    "    input_dim_e = input_dim_x\n",
    "\n",
    "    ckpt_layers = infer_ckpt_num_layers(state)\n",
    "\n",
    "    # - num_heads 안전 처리\n",
    "    num_heads = 12\n",
    "    if hidden_dim % num_heads != 0:\n",
    "        if verbose:\n",
    "            print(f\"[Warn] hidden_dim={hidden_dim} 이 num_heads=12로 나누어떨어지지 않음 → num_heads=1로 변경\")\n",
    "        num_heads = 1\n",
    "\n",
    "    # ============================================================\n",
    "    # (C) 모델 생성 + state_dict 로드\n",
    "    # ============================================================\n",
    "    model = CARTE_Base(\n",
    "        input_dim_x=input_dim_x,\n",
    "        input_dim_e=input_dim_e,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=int(num_layers),\n",
    "        ff_dim=int(ff_dim),\n",
    "        num_heads=int(num_heads),\n",
    "        concat=True,\n",
    "        dropout=0.0,\n",
    "    )\n",
    "\n",
    "    incompat = model.load_state_dict(state, strict=False)\n",
    "\n",
    "    # ============================================================\n",
    "    # (D) 안정성 체크: 핵심 파라미터 누락 시 즉시 중단\n",
    "    # ============================================================\n",
    "    must_prefix = (\"initial_x.\", \"initial_e.\", \"read_out_block.\")\n",
    "    critical_missing = [k for k in incompat.missing_keys if k.startswith(must_prefix)]\n",
    "    if critical_missing:\n",
    "        raise RuntimeError(\n",
    "            \"[LoadError] 핵심 파라미터 로드 실패 → 프리트레인 사용 불가 상태\\n\"\n",
    "            f\"  - sample: {critical_missing[:30]}\"\n",
    "        )\n",
    "\n",
    "    # ============================================================\n",
    "    # (E) 프리트레인 \"실제 주입\" 검증 (가장 확실한 체크)\n",
    "    # ============================================================\n",
    "    def _verify_pretrained_injected(\n",
    "        *,\n",
    "        model: CARTE_Base,\n",
    "        ckpt_state: Dict[str, torch.Tensor],\n",
    "        verbose: bool,\n",
    "    ) -> bool:\n",
    "        \"\"\"\n",
    "        - 목적\n",
    "          - ckpt_state가 model 파라미터에 실제로 주입되었는지 확정\n",
    "        - 방식\n",
    "          - 공통 키 중 '핵심 파라미터' 우선으로 allclose 비교\n",
    "        \"\"\"\n",
    "        model_state = model.state_dict()\n",
    "\n",
    "        # - 공통 키\n",
    "        common_keys = [k for k in ckpt_state.keys() if k in model_state]\n",
    "        if verbose:\n",
    "            print(f\"[Verify] common_keys={len(common_keys):,} / model_keys={len(model_state):,} / ckpt_keys={len(ckpt_state):,}\")\n",
    "\n",
    "        if not common_keys:\n",
    "            if verbose:\n",
    "                print(\"[Verify] 공통 키가 없습니다. → 구조 불일치/로딩 실패 가능성 큼\")\n",
    "            return False\n",
    "\n",
    "        # - 우선 확인할 핵심 키(없으면 common_keys에서 일부 사용)\n",
    "        priority_keys = [\n",
    "            \"initial_x.0.weight\",\n",
    "            \"initial_e.0.weight\",\n",
    "            \"read_out_block.g_attn.lin_query.weight\",\n",
    "            \"read_out_block.g_attn.lin_key.weight\",\n",
    "            \"read_out_block.g_attn.lin_value.weight\",\n",
    "        ]\n",
    "        check_keys = [k for k in priority_keys if k in common_keys]\n",
    "        if not check_keys:\n",
    "            check_keys = common_keys[:5]\n",
    "\n",
    "        matched = 0\n",
    "        for k in check_keys:\n",
    "            a = model_state[k].detach().cpu()\n",
    "            b = ckpt_state[k].detach().cpu()\n",
    "            same = torch.allclose(a, b)\n",
    "            matched += int(same)\n",
    "            if verbose:\n",
    "                print(f\"[Verify] {k} allclose={same} shape={tuple(a.shape)}\")\n",
    "\n",
    "        injected = matched > 0\n",
    "        if verbose:\n",
    "            print(f\"[Verify] injected={injected} (matched {matched}/{len(check_keys)})\")\n",
    "        return injected\n",
    "\n",
    "    injected = _verify_pretrained_injected(model=model, ckpt_state=state, verbose=verbose)\n",
    "    if not injected:\n",
    "        raise RuntimeError(\n",
    "            \"[VerifyError] 체크포인트가 모델에 실제로 주입되지 않았습니다.\\n\"\n",
    "            \"- prefix 제거/모델 구조/체크포인트 파일을 확인하세요.\"\n",
    "        )\n",
    "\n",
    "    # ============================================================\n",
    "    # (F) 로깅 + 디바이스 이동\n",
    "    # ============================================================\n",
    "    if verbose:\n",
    "        print(f\"[Model] input_dim_x={input_dim_x} input_dim_e={input_dim_e} hidden_dim={hidden_dim} ff_dim={ff_dim} heads={num_heads}\")\n",
    "        print(f\"[Model] num_layers={num_layers} (ckpt_layers≈{ckpt_layers}) | 실제 MP≈{num_layers + 1}(readout 포함)\")\n",
    "        print(f\"[LoadState] missing_keys={len(incompat.missing_keys)} unexpected_keys={len(incompat.unexpected_keys)}\")\n",
    "        print(\"  - missing sample:\", incompat.missing_keys[:20])\n",
    "        print(\"  - unexpected sample:\", incompat.unexpected_keys[:20])\n",
    "        print(\"[OK] pretrained weights injected ✅\")\n",
    "\n",
    "    model = model.to(torch.device(device))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# (5) Graphlet 생성 (fastText 다운로드 포함)\n",
    "# ============================================================\n",
    "def build_graphlets_from_table(\n",
    "    X: pd.DataFrame,\n",
    "    *,\n",
    "    verbose: bool,\n",
    ") -> List[Any]:\n",
    "    \"\"\"\n",
    "    - 목적\n",
    "      - (numeric + text slot) 테이블 -> graphlet 리스트 생성\n",
    "    \"\"\"\n",
    "    fasttext_bin_path = hf_hub_download(\n",
    "        repo_id=\"hi-paris/fastText\",\n",
    "        filename=\"cc.en.300.bin\",\n",
    "    )\n",
    "\n",
    "    preprocessor = Table2GraphTransformer(\n",
    "        lm_model=\"fasttext\",\n",
    "        fasttext_model_path=fasttext_bin_path,\n",
    "    )\n",
    "\n",
    "    # - 주의: fit_transform이므로, 내부 사전/처리 상태를 X에 맞춰 구성\n",
    "    graphs = preprocessor.fit_transform(X)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[Graphlets] count={len(graphs):,}\")\n",
    "\n",
    "        # - 샘플 1개 shape 확인(가능할 때만)\n",
    "        try:\n",
    "            g0 = graphs[0]\n",
    "            x_shape = tuple(getattr(g0, \"x\").shape)\n",
    "            e_shape = tuple(getattr(g0, \"edge_attr\").shape)\n",
    "            print(f\"[Graphlets] sample0 x={x_shape} edge_attr={e_shape}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return graphs\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# (6) Head embedding 추출\n",
    "# ============================================================\n",
    "def get_head_indices_from_batch(batch: Any) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    - 목적\n",
    "      - 배치에서 graph별 head 인덱스 추출\n",
    "    - 우선순위\n",
    "      1) batch.head_idx 존재 시 사용(가정 최소화)\n",
    "      2) 없으면 ptr[:-1] 사용(첫 노드가 head라는 가정)\n",
    "    \"\"\"\n",
    "    if hasattr(batch, \"head_idx\"):\n",
    "        head_idx = getattr(batch, \"head_idx\")\n",
    "        if torch.is_tensor(head_idx):\n",
    "            return head_idx\n",
    "        return torch.as_tensor(head_idx, device=batch.x.device)\n",
    "\n",
    "    if hasattr(batch, \"ptr\"):\n",
    "        return batch.ptr[:-1]\n",
    "\n",
    "    raise RuntimeError(\"Batch에 head_idx/ptr이 없습니다. (PyG DataLoader/그래프 생성 확인 필요)\")\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_head_embeddings(\n",
    "    graphs: List[Any],\n",
    "    *,\n",
    "    model: CARTE_Base,\n",
    "    batch_size: int,\n",
    "    device: str,\n",
    "    verbose: bool,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    - 목적\n",
    "      - 각 graphlet의 head node embedding 추출\n",
    "    \"\"\"\n",
    "    if not graphs:\n",
    "        raise ValueError(\"graphs가 비어있습니다.\")\n",
    "\n",
    "    loader = DataLoader(graphs, batch_size=int(batch_size), shuffle=False)\n",
    "\n",
    "    outs: List[np.ndarray] = []\n",
    "    for step, batch in enumerate(loader, start=1):\n",
    "        batch = batch.to(torch.device(device))\n",
    "\n",
    "        x_out = model(batch.x, batch.edge_index, batch.edge_attr)  # (total_nodes, hidden_dim)\n",
    "        head_idx = get_head_indices_from_batch(batch)\n",
    "\n",
    "        head_emb = x_out[head_idx].detach().cpu().numpy()\n",
    "        outs.append(head_emb)\n",
    "\n",
    "        if verbose and step == 1:\n",
    "            print(f\"[Embed] batch1 head_emb shape={head_emb.shape}\")\n",
    "\n",
    "    emb = np.vstack(outs)\n",
    "\n",
    "    # - 안정성 체크(무한/NaN 방지)\n",
    "    if not np.isfinite(emb).all():\n",
    "        raise ValueError(\"[EmbedError] embedding에 NaN/Inf가 포함되어 있습니다.\")\n",
    "\n",
    "    return emb\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# (7) 파이프라인\n",
    "# ============================================================\n",
    "def run_pipeline(cfg: RunConfig, *, schema: CatalogSchema) -> Path:\n",
    "    \"\"\"\n",
    "    - 목적\n",
    "      - movie_catalog_flat.parquet -> movie_embeddings.parquet 생성\n",
    "    \"\"\"\n",
    "    if not cfg.input_path.exists():\n",
    "        raise FileNotFoundError(f\"input_path not found: {cfg.input_path}\")\n",
    "\n",
    "    cfg.out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if cfg.verbose:\n",
    "        print(f\"[IO] input={cfg.input_path}\")\n",
    "        print(f\"[IO] output={cfg.out_path}\")\n",
    "        print(f\"[IO] ckpt={cfg.pretrained_model_path}\")\n",
    "\n",
    "    # 1) load catalog\n",
    "    df_raw = pd.read_parquet(cfg.input_path)\n",
    "\n",
    "    # 2) standardize -> X 만들기\n",
    "    X, movie_ids = build_model_input_table(df_raw, schema=schema, verbose=cfg.verbose)\n",
    "\n",
    "    # 3) table -> graphlets\n",
    "    graphs = build_graphlets_from_table(X, verbose=cfg.verbose)\n",
    "\n",
    "    # 4) load model\n",
    "    model = load_carte_base(\n",
    "        pretrained_model_path=cfg.pretrained_model_path,\n",
    "        device=cfg.device,\n",
    "        num_layers=int(cfg.num_layers),\n",
    "        verbose=cfg.verbose,\n",
    "    )\n",
    "\n",
    "    # 5) extract embeddings\n",
    "    emb = extract_head_embeddings(\n",
    "        graphs,\n",
    "        model=model,\n",
    "        batch_size=int(cfg.batch_size),\n",
    "        device=cfg.device,\n",
    "        verbose=cfg.verbose,\n",
    "    )\n",
    "\n",
    "    # 6) save parquet\n",
    "    out_df = pd.DataFrame(\n",
    "        {\n",
    "            schema.id_col: movie_ids,\n",
    "            \"embedding\": [e.astype(np.float32).tolist() for e in emb],\n",
    "        }\n",
    "    )\n",
    "    out_df.to_parquet(cfg.out_path, index=False)\n",
    "\n",
    "    if cfg.verbose:\n",
    "        print(f\"[OK] saved: {cfg.out_path} rows={len(out_df):,} dim={emb.shape[1]} device={cfg.device} num_layers={cfg.num_layers}\")\n",
    "\n",
    "    return cfg.out_path\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# (8) CLI / Notebook helper\n",
    "# ============================================================\n",
    "def build_parser() -> argparse.ArgumentParser:\n",
    "    p = argparse.ArgumentParser(add_help=True)\n",
    "    p.add_argument(\"--input_path\", type=str, required=True, help=\"movie_catalog_flat.parquet 경로\")\n",
    "    p.add_argument(\"--out_path\", type=str, required=True, help=\"movie_embeddings.parquet 저장 경로\")\n",
    "    p.add_argument(\"--pretrained_model_path\", type=str, default=\"\", help=\"비우면 config_directory['pretrained_model'] 사용\")\n",
    "    p.add_argument(\"--batch_size\", type=int, default=256)\n",
    "    p.add_argument(\"--device\", type=str, default=\"\")\n",
    "    p.add_argument(\n",
    "        \"--num_layers\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"CARTE_Base 내부 layers 개수 (주의: 실제 MP≈num_layers+1(readout 포함)). oversmoothing이면 0도 테스트 권장\",\n",
    "    )\n",
    "    p.add_argument(\"--verbose\", action=\"store_true\")\n",
    "    return p\n",
    "\n",
    "\n",
    "def resolve_pretrained_path(user_path: str) -> Path:\n",
    "    \"\"\"\n",
    "    - 목적\n",
    "      - pretrained 경로 결정\n",
    "    \"\"\"\n",
    "    if user_path.strip():\n",
    "        return Path(user_path.strip())\n",
    "\n",
    "    default_path = str(config_directory.get(\"pretrained_model\", \"\")).strip()\n",
    "    if not default_path:\n",
    "        raise ValueError(\"pretrained_model_path가 비어있습니다. (config_directory['pretrained_model'] 확인 필요)\")\n",
    "    return Path(default_path)\n",
    "\n",
    "\n",
    "def main(argv: Optional[List[str]] = None) -> None:\n",
    "    args = build_parser().parse_args(argv)\n",
    "\n",
    "    schema = CatalogSchema()\n",
    "\n",
    "    cfg = RunConfig(\n",
    "        input_path=Path(args.input_path),\n",
    "        out_path=Path(args.out_path),\n",
    "        pretrained_model_path=resolve_pretrained_path(args.pretrained_model_path),\n",
    "        batch_size=int(args.batch_size),\n",
    "        device=build_device(args.device),\n",
    "        num_layers=int(args.num_layers),\n",
    "        verbose=bool(args.verbose),\n",
    "    )\n",
    "\n",
    "    run_pipeline(cfg, schema=schema)\n",
    "\n",
    "\n",
    "def run_in_notebook(\n",
    "    *,\n",
    "    project_root: str = \"/content/drive/MyDrive/대학원/논문/CARTE\",\n",
    "    input_rel: str = \"data/processed/movie_catalog_flat.parquet\",\n",
    "    out_rel: str = \"data/processed/movie_embeddings.parquet\",\n",
    "    batch_size: int = 256,\n",
    "    device: Optional[str] = None,\n",
    "    num_layers: int = 1,\n",
    "    verbose: bool = True,\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    - 목적\n",
    "      - 노트북에서 간단 실행\n",
    "    \"\"\"\n",
    "    schema = CatalogSchema()\n",
    "    root = Path(project_root)\n",
    "\n",
    "    cfg = RunConfig(\n",
    "        input_path=root / input_rel,\n",
    "        out_path=root / out_rel,\n",
    "        pretrained_model_path=resolve_pretrained_path(\"\"),\n",
    "        batch_size=int(batch_size),\n",
    "        device=build_device(device),\n",
    "        num_layers=int(num_layers),\n",
    "        verbose=bool(verbose),\n",
    "    )\n",
    "\n",
    "    return run_pipeline(cfg, schema=schema)\n",
    "\n",
    "\n",
    "# ✅ 노트북에서는 자동 실행 금지\n",
    "if __name__ == \"__main__\" and not is_ipython_env():\n",
    "    main()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# (9) 노트북 실행 예시(직접 호출)\n",
    "# ============================================================\n",
    "out_path = run_in_notebook(\n",
    "    project_root=\"/content/drive/MyDrive/대학원/논문/CARTE\",\n",
    "    input_rel=\"data/processed/movie_catalog_flat.parquet\",\n",
    "    out_rel=\"data/processed/movie_embeddings.parquet\",\n",
    "    batch_size=256,\n",
    "    device=None,\n",
    "    num_layers=0,\n",
    "    verbose=True,\n",
    ")\n",
    "print(\"saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1767278057452,
     "user": {
      "displayName": "J K",
      "userId": "02403182054655897372"
     },
     "user_tz": -540
    },
    "id": "KYLKFEpL2dBa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2490,
     "status": "ok",
     "timestamp": 1767278299689,
     "user": {
      "displayName": "J K",
      "userId": "02403182054655897372"
     },
     "user_tz": -540
    },
    "id": "rUXRZ8Jz-C0Y",
    "outputId": "699a7079-69d4-4d4a-f212-cb41a4c96b14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Embedding Diagnostics ==========\n",
      "[Path] /content/drive/MyDrive/대학원/논문/CARTE/data/processed/movie_embeddings.parquet\n",
      "[Shape] N=86,272 D=300\n",
      "\n",
      "[Finite] ratio=1.00000000\n",
      "\n",
      "[Norms]\n",
      "  - min=11.210655\n",
      "  - p25=13.306205\n",
      "  - p50=13.443941\n",
      "  - p75=13.573166\n",
      "  - max=14.516237\n",
      "  - zero_norm_ratio=0.00000000\n",
      "\n",
      "[movieId unique] ratio=1.00000000\n",
      "\n",
      "[Embedding uniqueness] (sample=20,000) unique_ratio=0.999100\n",
      "\n",
      "[Per-dimension std] (sample 기반)\n",
      "  - std_min=8.914248e-03\n",
      "  - std_med=1.409741e-01\n",
      "  - std_max=4.092232e-01\n",
      "  - dead_dim_ratio(std<1e-4)=0.000000\n",
      "  - lowvar_dim_ratio(std<0.1*median)=0.003333\n",
      "\n",
      "[Anisotropy] (sample 기반)\n",
      "  - ||mean(normalized)|| = 0.974635  (작을수록 골고루)\n",
      "  - cos(x, mean_dir) stats\n",
      "    * mean=0.974634, std=0.045045\n",
      "    * p5=0.930868, p50=0.983698, p95=0.997269\n",
      "  - WARNING: 평균 방향 쏠림이 큰 편(이방성) → 임베딩이 한쪽으로 몰릴 수 있음\n",
      "\n",
      "[Pairwise cosine similarity] (random pairs)\n",
      "  - pairs=200,000\n",
      "  - mean=0.949908, std=0.071041\n",
      "  - p1=0.734901\n",
      "  - p5=0.849358\n",
      "  - p50=0.969802\n",
      "  - p95=0.995319\n",
      "  - p99=0.997838\n",
      "\n",
      "[PCA variance ratio] (sample 기반)\n",
      "  - EVR@1  = 0.6907\n",
      "  - EVR@5  = 0.9738\n",
      "  - EVR@10 = 0.9949\n",
      "  - effective_rank ≈ 3.08 (클수록 골고루)\n",
      "  - WARNING: 1개 주성분이 20% 초과 → 특정 축 쏠림 가능\n",
      "  - WARNING: 상위 10개 주성분이 70% 초과 → 저차원으로 붕괴 가능\n",
      "\n",
      "[Catalog] title 컬럼이 없어서 제목 출력은 생략합니다.\n",
      "\n",
      "========== Done ==========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# 설정 (경로/컬럼명)\n",
    "# ============================================================\n",
    "PROJECT_ROOT = Path(\"/content/drive/MyDrive/대학원/논문/CARTE\")\n",
    "EMB_PATH = PROJECT_ROOT / \"data/processed/movie_embeddings.parquet\"\n",
    "CATALOG_PATH = PROJECT_ROOT / \"data/processed/movie_catalog_flat.parquet\"  # 없으면 None로\n",
    "\n",
    "ID_COL = \"movieId\"\n",
    "EMB_COL = \"embedding\"\n",
    "\n",
    "# ============================================================\n",
    "# 로더: parquet -> (movie_ids, E)\n",
    "# ============================================================\n",
    "def load_embedding_matrix(\n",
    "    emb_path: Path,\n",
    "    *,\n",
    "    id_col: str = ID_COL,\n",
    "    emb_col: str = EMB_COL,\n",
    "    expected_dim: Optional[int] = 300,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    - 목적\n",
    "      - embedding parquet 로드\n",
    "      - embedding(list) -> (N, D) float32 변환\n",
    "    \"\"\"\n",
    "    df = pd.read_parquet(emb_path)\n",
    "    if id_col not in df.columns or emb_col not in df.columns:\n",
    "        raise ValueError(f\"[SchemaError] 필요 컬럼 없음: {id_col}, {emb_col} | got={list(df.columns)}\")\n",
    "\n",
    "    movie_ids = pd.to_numeric(df[id_col], errors=\"coerce\")\n",
    "    if movie_ids.isna().any():\n",
    "        bad = df.loc[movie_ids.isna(), id_col].head(10).tolist()\n",
    "        raise ValueError(f\"[DataError] movieId 숫자 변환 실패. sample={bad}\")\n",
    "    movie_ids = movie_ids.astype(np.int64).to_numpy()\n",
    "\n",
    "    emb_list = df[emb_col].tolist()\n",
    "    if len(emb_list) == 0:\n",
    "        raise ValueError(\"[DataError] embedding 테이블이 비었습니다.\")\n",
    "\n",
    "    first = np.asarray(emb_list[0], dtype=np.float32)\n",
    "    if first.ndim != 1:\n",
    "        raise ValueError(f\"[DataError] embedding[0]가 1D가 아님: {first.shape}\")\n",
    "\n",
    "    dim = int(first.shape[0])\n",
    "    if expected_dim is not None and dim != expected_dim:\n",
    "        raise ValueError(f\"[DimError] expected_dim={expected_dim}, got_dim={dim}\")\n",
    "\n",
    "    E = np.empty((len(emb_list), dim), dtype=np.float32)\n",
    "    for i, v in enumerate(emb_list):\n",
    "        a = np.asarray(v, dtype=np.float32)\n",
    "        if a.ndim != 1 or a.shape[0] != dim:\n",
    "            raise ValueError(f\"[DimError] row={i} dim mismatch. expected={dim}, got={a.shape}\")\n",
    "        E[i] = a\n",
    "\n",
    "    return movie_ids, E\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 진단: \"골고루 분포\" 체크 (수치로)\n",
    "# ============================================================\n",
    "def run_embedding_diagnostics(\n",
    "    *,\n",
    "    emb_path: Path,\n",
    "    catalog_path: Optional[Path] = None,\n",
    "    expected_dim: int = 300,\n",
    "    row_sample_size: int = 20000,\n",
    "    pair_sample_size: int = 200000,\n",
    "    seed: int = 7,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    - 목적\n",
    "      - embedding이 \"골고루 분포\" 되었는지(붕괴/쏠림/이방성) 점검\n",
    "    - 포함 체크\n",
    "      1) 유한값/노름/중복\n",
    "      2) 차원별 분산(죽은 차원 비율)\n",
    "      3) 평균 방향 쏠림(이방성) 지표\n",
    "      4) 코사인 유사도 분포(랜덤 쌍 샘플링)\n",
    "      5) PCA(샘플) 설명분산비: 한두 축에 과도하게 몰리면 의심\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # ----------------------------\n",
    "    # (1) load\n",
    "    # ----------------------------\n",
    "    movie_ids, E = load_embedding_matrix(emb_path, expected_dim=expected_dim)\n",
    "    n, d = E.shape\n",
    "    print(f\"\\n========== Embedding Diagnostics ==========\")\n",
    "    print(f\"[Path] {emb_path}\")\n",
    "    print(f\"[Shape] N={n:,} D={d}\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # (2) 기본 정상성\n",
    "    # ----------------------------\n",
    "    finite_ratio = float(np.isfinite(E).mean())\n",
    "    print(f\"\\n[Finite] ratio={finite_ratio:.8f}\")\n",
    "    if finite_ratio < 1.0:\n",
    "        bad_cnt = int((~np.isfinite(E)).sum())\n",
    "        print(f\"  - WARNING: non-finite count={bad_cnt}\")\n",
    "\n",
    "    norms = np.linalg.norm(E, axis=1)\n",
    "    print(\"\\n[Norms]\")\n",
    "    print(f\"  - min={float(norms.min()):.6f}\")\n",
    "    print(f\"  - p25={float(np.quantile(norms, 0.25)):.6f}\")\n",
    "    print(f\"  - p50={float(np.median(norms)):.6f}\")\n",
    "    print(f\"  - p75={float(np.quantile(norms, 0.75)):.6f}\")\n",
    "    print(f\"  - max={float(norms.max()):.6f}\")\n",
    "    print(f\"  - zero_norm_ratio={float((norms == 0).mean()):.8f}\")\n",
    "\n",
    "    uniq_id_ratio = len(np.unique(movie_ids)) / len(movie_ids)\n",
    "    print(f\"\\n[movieId unique] ratio={uniq_id_ratio:.8f}\")\n",
    "    if uniq_id_ratio < 1.0:\n",
    "        print(\"  - WARNING: duplicated movieId 존재\")\n",
    "\n",
    "    # - embedding 중복(샘플 기반)\n",
    "    sample_n = min(n, row_sample_size)\n",
    "    sample_idx = rng.choice(n, size=sample_n, replace=False)\n",
    "    E_s = E[sample_idx]\n",
    "\n",
    "    #   - float 직접 비교는 불안정 → 소수점 반올림 후 bytes 해시\n",
    "    E_round = np.round(E_s, 4)\n",
    "    hashes = np.fromiter((hash(row.tobytes()) for row in E_round), dtype=np.int64, count=sample_n)\n",
    "    uniq_vec_ratio = len(np.unique(hashes)) / len(hashes)\n",
    "    print(f\"\\n[Embedding uniqueness] (sample={sample_n:,}) unique_ratio={uniq_vec_ratio:.6f}\")\n",
    "    if uniq_vec_ratio < 0.98:\n",
    "        print(\"  - WARNING: 동일/유사 벡터가 많이 존재할 수 있음(붕괴 의심)\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # (3) 차원별 분산(죽은 차원) 체크\n",
    "    # ----------------------------\n",
    "    # - 샘플에서 차원별 표준편차 확인\n",
    "    dim_std = E_s.std(axis=0)\n",
    "    dim_std_min = float(dim_std.min())\n",
    "    dim_std_med = float(np.median(dim_std))\n",
    "    dim_std_max = float(dim_std.max())\n",
    "    dead_dim_ratio = float((dim_std < 1e-4).mean())  # 거의 변하지 않는 차원 비율\n",
    "    lowvar_dim_ratio = float((dim_std < (0.1 * dim_std_med + 1e-12)).mean())  # 중앙값 대비 매우 낮은 차원 비율\n",
    "\n",
    "    print(\"\\n[Per-dimension std] (sample 기반)\")\n",
    "    print(f\"  - std_min={dim_std_min:.6e}\")\n",
    "    print(f\"  - std_med={dim_std_med:.6e}\")\n",
    "    print(f\"  - std_max={dim_std_max:.6e}\")\n",
    "    print(f\"  - dead_dim_ratio(std<1e-4)={dead_dim_ratio:.6f}\")\n",
    "    print(f\"  - lowvar_dim_ratio(std<0.1*median)={lowvar_dim_ratio:.6f}\")\n",
    "    if dead_dim_ratio > 0.05:\n",
    "        print(\"  - WARNING: '죽은 차원'이 5% 초과 → 임베딩 붕괴/전처리 문제 가능\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # (4) 이방성(한 방향으로 쏠림) 체크\n",
    "    # ----------------------------\n",
    "    # - 코사인 계산을 위해 정규화\n",
    "    E_s_norm = E_s / (np.linalg.norm(E_s, axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "    # (a) 평균 방향 벡터의 길이: 0에 가까울수록 '골고루'(등방성)에 가까움\n",
    "    mean_dir = E_s_norm.mean(axis=0)\n",
    "    mean_dir_norm = float(np.linalg.norm(mean_dir))\n",
    "    print(\"\\n[Anisotropy] (sample 기반)\")\n",
    "    print(f\"  - ||mean(normalized)|| = {mean_dir_norm:.6f}  (작을수록 골고루)\")\n",
    "\n",
    "    # (b) 평균 방향과의 코사인 분포\n",
    "    cos_to_mean = E_s_norm @ (mean_dir / (np.linalg.norm(mean_dir) + 1e-12))\n",
    "    print(\"  - cos(x, mean_dir) stats\")\n",
    "    print(f\"    * mean={float(cos_to_mean.mean()):.6f}, std={float(cos_to_mean.std()):.6f}\")\n",
    "    print(f\"    * p5={float(np.quantile(cos_to_mean, 0.05)):.6f}, p50={float(np.median(cos_to_mean)):.6f}, p95={float(np.quantile(cos_to_mean, 0.95)):.6f}\")\n",
    "    if mean_dir_norm > 0.10:\n",
    "        print(\"  - WARNING: 평균 방향 쏠림이 큰 편(이방성) → 임베딩이 한쪽으로 몰릴 수 있음\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # (5) 랜덤 쌍 코사인 유사도 분포(골고루 vs 뭉침)\n",
    "    # ----------------------------\n",
    "    # - 랜덤으로 두 점을 뽑아 코사인 유사도 분포 확인\n",
    "    pair_m = min(pair_sample_size, sample_n * 20)  # 과도한 샘플 방지\n",
    "    a_idx = rng.integers(0, sample_n, size=pair_m)\n",
    "    b_idx = rng.integers(0, sample_n, size=pair_m)\n",
    "\n",
    "    # - 동일 인덱스 제거(가능하면)\n",
    "    same = a_idx == b_idx\n",
    "    if same.any():\n",
    "        b_idx[same] = (b_idx[same] + 1) % sample_n\n",
    "\n",
    "    pair_cos = np.sum(E_s_norm[a_idx] * E_s_norm[b_idx], axis=1)\n",
    "\n",
    "    print(\"\\n[Pairwise cosine similarity] (random pairs)\")\n",
    "    print(f\"  - pairs={pair_m:,}\")\n",
    "    print(f\"  - mean={float(pair_cos.mean()):.6f}, std={float(pair_cos.std()):.6f}\")\n",
    "    print(f\"  - p1={float(np.quantile(pair_cos, 0.01)):.6f}\")\n",
    "    print(f\"  - p5={float(np.quantile(pair_cos, 0.05)):.6f}\")\n",
    "    print(f\"  - p50={float(np.median(pair_cos)):.6f}\")\n",
    "    print(f\"  - p95={float(np.quantile(pair_cos, 0.95)):.6f}\")\n",
    "    print(f\"  - p99={float(np.quantile(pair_cos, 0.99)):.6f}\")\n",
    "\n",
    "    # - 지나치게 모든 쌍이 비슷하면(평균이 높고 분산이 낮음) 뭉침 의심\n",
    "    if float(pair_cos.mean()) > 0.20 and float(pair_cos.std()) < 0.05:\n",
    "        print(\"  - WARNING: 랜덤 쌍 코사인이 전반적으로 높고 분산이 작음 → 임베딩이 뭉친(붕괴) 가능성\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # (6) PCA 설명분산(샘플) — 특정 축에 과도하게 몰리면 '쏠림'\n",
    "    # ----------------------------\n",
    "    # - numpy SVD로 PCA (중심화 후)\n",
    "    X = E_s - E_s.mean(axis=0, keepdims=True)\n",
    "    # - full SVD는 느릴 수 있음: sample_n을 적당히 유지\n",
    "    # - singular values: s (내림차순)\n",
    "    try:\n",
    "        _, s, _ = np.linalg.svd(X, full_matrices=False)\n",
    "        var = (s**2) / (sample_n - 1)\n",
    "        var_ratio = var / (var.sum() + 1e-12)\n",
    "\n",
    "        top1 = float(var_ratio[0])\n",
    "        top5 = float(var_ratio[:5].sum())\n",
    "        top10 = float(var_ratio[:10].sum())\n",
    "        # - effective rank (exp(entropy))\n",
    "        p = var_ratio / (var_ratio.sum() + 1e-12)\n",
    "        eff_rank = float(np.exp(-(p * np.log(p + 1e-12)).sum()))\n",
    "\n",
    "        print(\"\\n[PCA variance ratio] (sample 기반)\")\n",
    "        print(f\"  - EVR@1  = {top1:.4f}\")\n",
    "        print(f\"  - EVR@5  = {top5:.4f}\")\n",
    "        print(f\"  - EVR@10 = {top10:.4f}\")\n",
    "        print(f\"  - effective_rank ≈ {eff_rank:.2f} (클수록 골고루)\")\n",
    "\n",
    "        if top1 > 0.20:\n",
    "            print(\"  - WARNING: 1개 주성분이 20% 초과 → 특정 축 쏠림 가능\")\n",
    "        if top10 > 0.70:\n",
    "            print(\"  - WARNING: 상위 10개 주성분이 70% 초과 → 저차원으로 붕괴 가능\")\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"\\n[PCA] WARNING: SVD 실패(수치 문제). 샘플 크기 줄이거나 non-finite 여부 확인 필요\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # (7) (옵션) 제목 3개 샘플 출력 (매칭 확인용)\n",
    "    # ----------------------------\n",
    "    if catalog_path is not None and Path(catalog_path).exists():\n",
    "        df_cat = pd.read_parquet(catalog_path)\n",
    "        if ID_COL in df_cat.columns and \"title\" in df_cat.columns:\n",
    "            cat_map = df_cat.set_index(ID_COL)[\"title\"]\n",
    "            print(\"\\n[Sample titles]\")\n",
    "            for mid in movie_ids[:3]:\n",
    "                title = cat_map.get(int(mid), None)\n",
    "                print(f\"  - movieId={int(mid)} | title={title}\")\n",
    "        else:\n",
    "            print(\"\\n[Catalog] title 컬럼이 없어서 제목 출력은 생략합니다.\")\n",
    "\n",
    "    print(\"\\n========== Done ==========\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 실행\n",
    "# ============================================================\n",
    "run_embedding_diagnostics(\n",
    "    emb_path=EMB_PATH,\n",
    "    catalog_path=CATALOG_PATH,   # 제목 확인 싫으면 None\n",
    "    expected_dim=300,\n",
    "    row_sample_size=20000,       # 너무 크면 느림 → 5,000~20,000 추천\n",
    "    pair_sample_size=200000,     # 너무 크면 느림 → 50,000~200,000 추천\n",
    "    seed=7,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMFDc9gSGWbMftBbT2IM9FZ",
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
